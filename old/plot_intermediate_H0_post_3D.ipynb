{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plan to obtain intermediate H0 from single df of single filter model of lenstronomy and overplot the posterior\n",
    "\"\"\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import argparse\n",
    "import importlib\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import corner,pickle\n",
    "import json,copy,time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import norm as normal\n",
    "\n",
    "from tools import *\n",
    "import pycs_get_res\n",
    "from get_res import *\n",
    "from Dt_from_Df import *\n",
    "from plotting_tools import base_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('figure',**{'figsize':(12,9)})\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Litt. Data\n",
    "h0planck = 67.4 # km/s/Mpc\n",
    "h0planck_err = 0.5\n",
    "h0licow  = 73.3 # km/s/Mpc\n",
    "h0licow_err = [1.8,1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_center(bins):\n",
    "    if len(np.shape(bins))==1: #so it works for 1D too\n",
    "        bins=[bins]\n",
    "    bins_centers = []\n",
    "    for i in range(len(bins)):\n",
    "        bins_centers_i = []\n",
    "        for j in range(len(bins[i])-1):\n",
    "            bins_centers_i.append((bins[i][j]+bins[i][j+1])/2.)\n",
    "        bins_centers.append(bins_centers_i)\n",
    "    bins_centers =np.array(bins_centers)\n",
    "    return bins_centers\n",
    "\n",
    "def err_Df(err_dt,h0):\n",
    "    # Convert sigma dt in sigma dphi \n",
    "    #-> simply the sqrt of the covariance\n",
    "    cov_Df_ = cov_Df(err_dt**2,h0)\n",
    "    err_Df_ = np.sqrt(cov_Df_)\n",
    "    return err_Df_\n",
    "\n",
    "def get_analytic_density_1D(mean,err,bins,norm=None):\n",
    "    center_bins = get_bin_center(bins) \n",
    "    #grid_of_points = np.transpose(np.meshgrid(*center_bins))\n",
    "    dens  = normal.pdf(center_bins,loc=mean,scale=err)\n",
    "    if type(norm) is float or type(norm) is int:\n",
    "        dens/=norm\n",
    "    elif type(norm) is bool:\n",
    "        if norm:\n",
    "            dens/=np.sum(dens)\n",
    "    return dens\n",
    "\n",
    "\n",
    "def get_PH0_1D(Dens_f,\n",
    "            nd_bins,\n",
    "            Dt_kw,\n",
    "            H0=np.arange(35,100,.1)):#(Post_Df,Post_Df_bins,Dt_kw=dt_kws[dim_i])\n",
    "    PH0 = []\n",
    "    for h0 in H0:\n",
    "        kwargs_df = {\"mean\":Df_XY(copy.deepcopy(Dt_kw[\"mean\"]),h0),\n",
    "             \"err\":err_Df(copy.deepcopy(Dt_kw[\"err\"]),h0)}\n",
    "\n",
    "        Dens_f_trsf = get_analytic_density_1D(bins=copy.deepcopy(nd_bins),**kwargs_df)\n",
    "        Dens_tot    = copy.deepcopy(Dens_f)*Dens_f_trsf\n",
    "        # the integration in this case is nothing else then the sum over every bin, ie:\n",
    "        P_h0 = np.sum(Dens_tot)\n",
    "        if np.isnan(P_h0):\n",
    "            P_h0 = 0.\n",
    "        PH0.append(P_h0)\n",
    "    if np.sum(PH0)!=0:\n",
    "        PH0 = PH0/np.sum(PH0)\n",
    "    else:\n",
    "        print(\"WARNING: sum of PH0 == 0\")\n",
    "    return np.array(PH0),H0\n",
    "\n",
    "\n",
    "def quantiles_uncertainties(prob,sampling_prob,q=[0.16,.5,0.84],return_quantiles=False):\n",
    "    qnt    = []\n",
    "    integr = 0\n",
    "    for i in range(len(prob)):\n",
    "        integr+=prob[i]\n",
    "        for qi in q:\n",
    "            if integr-prob[i]<qi and integr>=qi:\n",
    "                qnt.append(sampling_prob[i])\n",
    "    if return_quantiles:\n",
    "        return qnt\n",
    "    else:\n",
    "        res     = qnt[1]\n",
    "        err_min = qnt[1]-qnt[0]\n",
    "        err_max = qnt[2]-qnt[1]\n",
    "        return (res,err_min,err_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data collected\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ################################\n",
    "    name_prog = sys.argv[0]\n",
    "    present_program(name_prog)\n",
    "    ################################\n",
    "    parser = argparse.ArgumentParser(description=\"Temporary plot of the posterior of H0 from the given lens models\")\n",
    "    parser.add_argument(\"-nb\",\"--number_bins\",type=int, dest=\"nbins\", default=100,\n",
    "                    help=\"Number of bins per dimension for the histog. sampling of the Df (be careful with it! too many bins can be catastrophic)\")\n",
    "    parser.add_argument('SETTING_FILES',nargs=\"+\",default=[],help=\"setting file(s) to consider\")\n",
    "    \n",
    "    parser.add_argument('-ln','--lensname',help=\"Lensname for time delay dataset to consider\",\n",
    "                        dest=\"lensname\", \n",
    "                        default=\"J1433\",action=\"store\")\n",
    "    parser.add_argument('-dn','--dataname',action='store',default=\"forcen\",\n",
    "                        help=\"Dataname for time delay dataset to consider\")\n",
    "\n",
    "    args  = parser.parse_args()\n",
    "    # bins for the fermat pot\n",
    "    bins  = args.nbins \n",
    "    setting_names =  args.SETTING_FILES\n",
    "    lensname = args.lensname\n",
    "    dataname = args.dataname\n",
    "    \n",
    "    #Dt:\n",
    "    print(\"Time delay result obtained from: \"+lensname+\"_\"+dataname)\n",
    "    pycs_path = \"./my_pycs_scripts/\"\n",
    "    dt_comb_res = pycs_get_res.get_combined_res(lensname+\"_\"+dataname,main_dir_path=pycs_path)\n",
    "    sys = dt_comb_res.error.sys\n",
    "    rnd = dt_comb_res.error.rnd\n",
    "    err_dt  = np.sqrt(np.array(sys)**2 + np.array(rnd)**2)\n",
    "    dt_kws  = [{\"mean\":dt_comb_res.results[i],\"err\":err_dt[i]} for i in range(len(err_dt))]\n",
    "    \n",
    "    backup_res_lnstr = \"./backup_results/\"\n",
    "    savefig_path     = backup_res_lnstr+\"/Post_H0/\"\n",
    "    mkdir(savefig_path)\n",
    "    \n",
    "    mcmc_Dfs = []\n",
    "    for i,sets in enumerate(setting_names):\n",
    "        print(\"setting:\",sets)\n",
    "        mcmc_fermat = get_mcmc_fermat(sets)\n",
    "        mcmc_Df     = np.transpose(mcmc_fermat)[1:]-np.transpose(mcmc_fermat)[0]\n",
    "        mcmc_c    = np.array(copy.deepcopy(mcmc_Df))\n",
    "        mcmc_BC   = mcmc_c[1] - mcmc_c[0]  # BC = C - B = (C-A)-(B-A) = AC - AB\n",
    "        mcmc_c[2] = mcmc_BC\n",
    "        mcmc_Df   = mcmc_c \n",
    "        if i==0:\n",
    "            print(\"WARNING: Given the low S/N of image D, I will discard here and instead consider Delta BC\")    \n",
    "            lcs = [\"AB\",\"AC\",\"BC\"] \n",
    "        mcmc_Dfs.append(mcmc_Df)\n",
    "        \n",
    "    H0s  = []\n",
    "    PH0s = []\n",
    "    legend_elements = []\n",
    "    f,axes = plt.subplots(2,2,figsize=(12,12)) \n",
    "    \n",
    "    for dim_i in range(len(mcmc_Df)): # each dimension/quadrant\n",
    "        if dim_i==0:\n",
    "            ax = axes[0][0]\n",
    "        elif dim_i==1:\n",
    "            ax = axes[1][0]\n",
    "        elif dim_i==2:\n",
    "            ax = axes[1][1]\n",
    "        else:\n",
    "            raise RuntimeError(\"\")\n",
    "        y_max = 0\n",
    "        for i,sets in enumerate(setting_names): #each setting\n",
    "            Post_Df,Post_Df_bins = np.histogram(mcmc_Dfs[i][dim_i],bins=bins,density=True)     \n",
    "            PH0,H0 = get_PH0_1D(Post_Df,Post_Df_bins,Dt_kw=dt_kws[dim_i])\n",
    "            ax.scatter(H0,PH0,c=base_colors[i],marker=\".\") # label=strip_setting_name(sets)\n",
    "            h0_res,err_min,err_max= quantiles_uncertainties(PH0,H0,return_quantiles=False)\n",
    "            yh0 = max(PH0)/2\n",
    "            str_res = str(np.round(h0_res,2))+\"$_{-\"+str(np.round(err_min,2))+\"}^{+\"+str(np.round(err_max,2))+\"}$\"\n",
    "            ax.scatter(h0_res,yh0,c=base_colors[i],label=str_res,marker=\".\")\n",
    "            ax.errorbar(h0_res,yh0,yerr=None,xerr=[[err_min],[err_max]],capsize=4,fmt=base_colors[i])\n",
    "            #ax.text(h0_res-.5*len(str((np.round(h0_res,2)))),yh0*1.05,str_res,c=base_colors[i])\n",
    "            ax.legend()\n",
    "            if dim_i==0:\n",
    "                legend_elements.append(Patch(facecolor=base_colors[i],label=strip_setting_name(sets)))\n",
    "            if max(PH0)>y_max:\n",
    "                y_max = max(PH0)\n",
    "        ax.set_ylim(0,y_max*1.1)\n",
    "        ax.axvline(h0planck,label=\"Planck\",c=\"r\",ls=\"--\")\n",
    "        ax.axvline(h0licow,label=\"H0LiCOW\",c=\"g\",ls=\"--\")\n",
    "        ax.fill_between(np.linspace(h0planck-h0planck_err,  h0planck+h0planck_err ), -10, 10, color='r', alpha=0.2)\n",
    "        ax.fill_between(np.linspace(h0licow-h0licow_err[0], h0licow+h0licow_err[1]), -10, 10, color='g', alpha=0.2)\n",
    "        ax.set_xlabel(\"$H_0$[km/s/Mpc] from \"+lcs[dim_i])\n",
    "        ax.set_ylabel(\"P($H_0$)\")\n",
    "    axdel=axes[0][-1]\n",
    "    axdel.legend(handles=legend_elements)\n",
    "    axdel.axis(\"off\")\n",
    "    f.suptitle(\"Compare $H_0$ posterior from individual filter's lens models for different LCs combinations\")\n",
    "    plt.tight_layout()\n",
    "    f.savefig(savefig_path+\"/compare_H0_3D.png\")\n",
    "    print(\"Created \"+savefig_path+\"/compare_H0_3D.png\")\n",
    "    \n",
    "    res_H0 = [H0s,PH0s]\n",
    "    with open(savefig_path+\"/H0s.pkl\",\"wb\") as f:\n",
    "        pickle.dump(res_H0,f)\n",
    "    success(name_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
