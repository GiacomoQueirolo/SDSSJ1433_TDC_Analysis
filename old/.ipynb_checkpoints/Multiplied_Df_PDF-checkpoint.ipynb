{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from old_Multiply_Df_PDF\n",
    "# now considering the change discussed the 1-2nd of February  '22\n",
    "# correction : we already obtained the POSTERIOR from the MCMC, no need to multiply for the prior of Df in principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os,sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json,pickle\n",
    "import pathlib as pth\n",
    "from corner import corner\n",
    "import matplotlib.pyplot as plt\n",
    "from lenstronomy.Util.sampling_util import sample_ball\n",
    "from lenstronomy.Sampling.Pool.multiprocessing import MultiPool\n",
    "\n",
    "#my libs\n",
    "from tools import *\n",
    "from get_res import *\n",
    "from Multiply_PDF import get_minmax\n",
    "from Prior import Df_prior, Df_prior_ABC\n",
    "from statistical_tools import get_bins_volume\n",
    "from combinedsetting_class import combined_setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Plot the multiplied posterior distribution of the Fermat potential difference from the given filters\",\n",
    "                            usage='pokus --help',)\n",
    "parser.add_argument(\"-c\", \"--cut_mcmc\", type=int, dest=\"cut_mcmc\", default=0,\n",
    "                    help=\"Cut the first <c> steps of the mcmc to ignore them\")\n",
    "parser.add_argument(\"-n\",\"--name\",type=str,dest=\"dir_name\", default=\".\",\n",
    "                    help=\"Directory name where to save the multiplied posteriors\")\n",
    "parser.add_argument(\"-nb\",\"--number_bins\",type=int, dest=\"nbins\", default=40,\n",
    "                    help=\"Number of bins per dimension (be careful with it! too many bins can be catastrophic)\")\n",
    "parser.add_argument(\"-ms\",\"--mcmc_steps\",type=int, dest=\"mcmc_steps\", default=1000,\n",
    "                    help=\"Number of steps for the MCMC sampling and plot\")\n",
    "parser.add_argument(\"-mp\",\"--mcmc_prior\",type=int, dest=\"mcmc_prior\", default=1000,\n",
    "                    help=\"Number of steps for the MCMC sampling of the Priors\")\n",
    "parser.add_argument(\"-KDE\", action=\"store_true\", dest=\"KDE\", default=False,\n",
    "                    help=\"Use KDE (Kernel Density Estimator) instead of histograms (WARNING:Very slow for high number of points and/or bins)\")\n",
    "parser.add_argument(\"-mcmc\",\"--MCMC\", action=\"store_true\", dest=\"mcmc\", default=False,\n",
    "                    help=\"Also do the MCMC integration of the posterior\")\n",
    "#parser.add_argument(\"-b\",\"--boundaries\", action=\"store_true\", dest=\"boundaries\", default=False,\n",
    "#                    help=\"Consider more precise but long prior: computer Df boundaries and sample only there\")\n",
    "parser.add_argument(\"-NOP\",\"--not_old_Prior\", action=\"store_false\", dest=\"old_prior\", default=True,\n",
    "                    help=\"If present it will compute the Prior again (might take a while), else look for previously computed ones\")\n",
    "\n",
    "parser.add_argument('SETTING_FILES',nargs=\"+\",default=[],help=\"setting file(s) to consider\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "cut_mcmc = int(args.cut_mcmc)\n",
    "dir_name = args.dir_name\n",
    "KDE = bool(args.KDE)\n",
    "nbins = int(args.nbins)\n",
    "mcmc  = bool(args.mcmc)\n",
    "mcmc_steps  = int(args.mcmc_steps)\n",
    "mcmc_prior  = int(args.mcmc_prior)\n",
    "old_prior   = bool(args.old_prior)\n",
    "setting_names =  args.SETTING_FILES  \n",
    "####################\n",
    "present_program(sys.argv[0])\n",
    "####################\n",
    "\n",
    "backup_path=\"backup_results\"\n",
    "main_savedir=\"PDF_multiplication_ABC\"\n",
    "\n",
    "filters       = [get_filter(st) for st in setting_names]\n",
    "savemcmc_path = [get_savemcmcpath(st) for st in  setting_names]\n",
    "save_dir  = create_dir_name(setting_names,save_dir=main_savedir,dir_name=dir_name,backup_path=backup_path,copy_settings=True)\n",
    "\n",
    "\n",
    "# for fermat potentials\n",
    "fermat_mcmc = [get_mcmc_fermat(st,backup_path) for st in setting_names]\n",
    "\n",
    "\n",
    "samples = []\n",
    "for mcmc_iT in fermat_mcmc:\n",
    "    cut_mcmc_scaled = int(len(mcmc_iT)*cut_mcmc/1000)\n",
    "    mcmc_i   = np.transpose(mcmc_iT[cut_mcmc_scaled:]) \n",
    "    mcmc_Dfi = mcmc_i[1:]-mcmc_i[0]\n",
    "    #############################################\n",
    "    #############################################    \n",
    "    #print(\"WARNING: Given the low S/N of image D, I will discard here and instead consider Delta BC\")    \n",
    "    #param_names=[r\"$\\Delta\\phi AB$\", r\"$\\Delta\\phi AC$\",r\"$\\Delta\\phi AD$\"]\n",
    "    mcmc_c    = np.array(copy.deepcopy(mcmc_Dfi))\n",
    "    mcmc_BC   = mcmc_c[1] - mcmc_c[0]  # BC = C - B = (C-A)-(B-A) = AC - AB\n",
    "    mcmc_c[2] = mcmc_BC\n",
    "    mcmc_Dfi  = mcmc_c \n",
    "    samples.append(mcmc_Dfi.tolist())\n",
    "print(\"WARNING: Given the low S/N of image D, I will discard here and instead consider Delta BC\")    \n",
    "from fermat_pot_analysis import labels_Df as param_names\n",
    "param_names[-1] = r\"$\\Delta\\phi BC$\"\n",
    "##################################################################################\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using it on my machine with dark style jupyter\n",
    "if my_machine():\n",
    "    plt.style.use(['classic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we make the 3D histogram #-> should i consider more complex idea? like kernels?\n",
    "# actually Kernels sounds better -> see KDE_Df_PDF and old/KDE_Df_PDF_example\n",
    "# the question then is, how to multiply them? \n",
    "# fit them at the bin center and multiply there -> another idea would be to keep the various KDE and compute them\n",
    "# only when needed at the needed position/ at no matter which binning size\n",
    "\n",
    "# we could do that But keep it going with the multiplication at the bin position for the plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to find the best one \n",
    "# -<> sklearn I know and it works, the other seems easier and more reliable\n",
    "# following https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html\n",
    "# i go for sklearn: \"While there are several versions of kernel density estimation\n",
    "# implemented in Python (notably in the SciPy and StatsModels packages),\n",
    "# I prefer to use Scikit-Learn's version because of its efficiency and flexibility.  \"\n",
    "# see Kernel-Density-Estimation_new.ipynb for the full notebook\n",
    "# SEE OLD NOTES IN old/KDE_exercise_2Feb.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we must compute the prior for the fermat potential P(Delta Phi)\n",
    "\n",
    "#Priors_Df = [Df_prior(setting_names[0],npoints=mcmc_prior)] #those are MCMC priors\n",
    "#name_prior_HRes = \"Prior_\"+\"_\".join(filters)+\"_highres.json\"\n",
    "#path_prior_HRes = backup_path+\"/\"+main_savedir+\"/\"+name_prior_HRes\n",
    "name_prior = \"kw_Prior_\"+\"_\".join(filters)+\".json\"\n",
    "path_prior = backup_path+\"/\"+main_savedir+\"/\"+name_prior\n",
    "#name_prior_LRes = \"Prior_\"+\"_\".join(filters)+\"_lowres.json\"\n",
    "#path_prior_LRes = backup_path+\"/\"+main_savedir+\"/\"+name_prior_LRes\n",
    "#no_old_prior_hr = False\n",
    "no_old_prior = False\n",
    "if old_prior:\n",
    "    try:\n",
    "        #Prior_Df_HRes = load_whatever(path_prior_HRes)\n",
    "        kw_Prior_Df = load_whatever(path_prior)\n",
    "        Prior_Df    = kw_Prior_Df[\"Prior\"]\n",
    "        NtotPrior   = kw_Prior_Df[\"Ntot\"]\n",
    "    except:\n",
    "        #no_old_prior_hr = True\n",
    "        no_old_prior = True\n",
    "    \"\"\"try:\n",
    "        Prior_Df_LRes = load_whatever(path_prior_LRes)\n",
    "    except:\n",
    "        no_old_prior_lr = True\n",
    "    \"\"\"\n",
    "#if no_old_prior_hr or no_old_prior_lr or not old_prior:\n",
    "if no_old_prior or not old_prior:\n",
    "    Df_boundaries = [get_minmax(samples,i) for i in range(3)]\n",
    "    \n",
    "    #if no_old_prior_hr or not old_prior:\n",
    "    if no_old_prior or not old_prior:\n",
    "        \"\"\"\n",
    "        Df_boundaries = None\n",
    "        if boundaries:\n",
    "            Df_boundaries = [get_minmax(samples,i) for i in range(3)]                   \n",
    "        Priors_Df = [Df_prior_ABC(sett,save_mcmc=True,npoints=min(mcmc_prior,500000),Df_boundaries=Df_boundaries) for sett in setting_names] #those are MCMC priors\n",
    "        \"\"\"\n",
    "        #Prior_Df = Df_prior_ABC(setting_names[0],save_mcmc=True,npoints=min(mcmc_prior,500000),Df_boundaries=Df_boundaries) \n",
    "        # We actually assume them to be ~identical priors \n",
    "        # we consider a high res. prior on the bounded region and a \n",
    "        # lower reson a larger region\n",
    "        #Prior_Df_HRes,NtotPrior = Df_prior_ABC(setting_names[0],save_mcmc=True,npoints=min(mcmc_prior,50000),Df_boundaries=Df_boundaries) \n",
    "        Prior_Df,NtotPrior = Df_prior_ABC(setting_names[0],save_mcmc=True,npoints=min(mcmc_prior,50000),Df_boundaries=Df_boundaries) \n",
    "        #Prior_Df_LRes = Df_prior_ABC(setting_names[0],save_mcmc=True,npoints=min(mcmc_prior,50000),Df_boundaries=None,output_name=\"mcmc_prior_Df_lowres\")\n",
    "        #pt = corner(np.array(Priors_Df[0]),labels=param_names,show_titles=True)\n",
    "        #pt.savefig(str(save_dir)+\"/mcmc_prior_Df_\"+setting_names[0].replace(\".py\",\"\")+\".pdf\")\n",
    "        #pt = corner(np.array(Prior_Df_LRes),labels=param_names,show_titles=True)\n",
    "        #pt.savefig(str(save_dir)+\"/mcmc_prior_Df_lowres\"+setting_names[0].replace(\".py\",\"\")+\".pdf\")\n",
    "        #pt = corner(np.array(Prior_Df_HRes),labels=param_names,show_titles=True)\n",
    "        pt = corner(np.array(Prior_Df),labels=param_names,show_titles=True)\n",
    "        #pt.savefig(str(save_dir)+\"/mcmc_prior_Df_highres\"+setting_names[0].replace(\".py\",\"\")+\".pdf\")\n",
    "        pt.savefig(str(save_dir)+\"/mcmc_prior_Df\"+setting_names[0].replace(\".py\",\"\")+\".pdf\")\n",
    "        # NOTE: not the same shape as the samples!\n",
    "        # samples.shape = (n filter, n dim, n point)*,    Priors_Df.shape = (n filter, n points, n dims)\n",
    "        # *: n point is usually not outputed by the np.shape bc samples have different number of points\n",
    "\n",
    "            #These priors are then multiplied and combined into a single prior using the same binning as\n",
    "            # the Combined_PDF so that it is the comparable and they are then combined according to \n",
    "            # the theory (see Notes.ipynb at the 16th of Feb)\n",
    "            # -> actually is only 1 prior, bc we assume them to be compatible\n",
    "        #save_json(Prior_Df_HRes,path_prior_HRes)\n",
    "        kw_Prior_Df = {\"Prior\":np.array(Prior_Df).tolist(),\"Ntot\":NtotPrior}\n",
    "        save_json(kw_Prior_Df,path_prior)\n",
    "        #save_json(Prior_Df_LRes,path_prior_LRes)\n",
    "\"\"\"    if no_old_prior_lr or not old_prior:\n",
    "        Prior_Df_LRes = Df_prior_ABC(setting_names[0],save_mcmc=True,npoints=min(mcmc_prior,50000),Df_boundaries=None,output_name=\"mcmc_prior_Df_lowres\")\n",
    "        pt = corner(np.array(Prior_Df_LRes),labels=param_names,show_titles=True)\n",
    "        pt.savefig(str(save_dir)+\"/mcmc_prior_Df_lowres\"+setting_names[0].replace(\".py\",\"\")+\".pdf\")\n",
    "        save_json(Prior_Df_LRes,path_prior_LRes)\n",
    "\"\"\"\n",
    "if KDE:\n",
    "    from Multiply_PDF import Multiply_PDF_KDE\n",
    "    npoints = nbins  # To TEST\n",
    "    #Combined_PDF,Positions_KDE = Multiply_PDF_KDE(samples,npoints,Priors=Priors_Df,savedir=save_dir)\n",
    "    #Combined_PDF,Positions_KDE = Multiply_PDF_KDE(samples,npoints,Prior_LR=Prior_Df_LRes,Prior_HR=Prior_Df_HRes,savedir=save_dir)\n",
    "    Combined_PDF,Positions_KDE = Multiply_PDF_KDE(samples,npoints,Prior=Prior_Df,NtotPrior=NtotPrior,savedir=save_dir)\n",
    "else:\n",
    "    from Multiply_PDF import Multiply_PDF_HIST\n",
    "    #Combined_PDF,Combined_bins = Multiply_PDF_HIST(samples,nbins,Priors=Priors_Df,savedir=save_dir)\n",
    "    #Combined_PDF,Combined_bins = Multiply_PDF_HIST(samples,nbins,Prior_LR=Prior_Df_LRes,Prior_HR=Prior_Df_HRes,savedir=save_dir)\n",
    "    Combined_PDF,Combined_bins = Multiply_PDF_HIST(samples,nbins,Prior=Prior_Df,NtotPrior=NtotPrior,savedir=save_dir)\n",
    "\n",
    "\n",
    "\n",
    "# The Combined_PDF must be re-normalised\n",
    "if KDE:\n",
    "    #Combined_PDF = Normalise_KDE(Combined_PDF,Positions_KDE)\n",
    "    Combined_PDF /= np.sum(Combined_PDF)\n",
    "    # still unclear how to do it in KDE\n",
    "else:\n",
    "    Combined_PDF /= np.sum(Combined_PDF*get_bins_volume(Combined_bins))\n",
    "\n",
    "\n",
    "with open(str(save_dir)+\"/Combined_PDF\"+[\"_KDE\" if KDE else \"\"][0]+\".pkl\",\"wb\") as f:\n",
    "    pickle.dump(Combined_PDF,f)\n",
    "    \n",
    "if KDE:\n",
    "    with open(str(save_dir)+\"/Combined_PDF_KDE_positions.pkl\",\"wb\") as f:\n",
    "        pickle.dump(Positions_KDE,f)\n",
    "else:\n",
    "    with open(str(save_dir)+\"/Combined_PDF_bins.pkl\",\"wb\") as f:\n",
    "        pickle.dump(Combined_bins,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create a small \"setting\" file with the name of the files and redshifts\n",
    "\n",
    "comment  = \"Product of posteriors done by \"+str(sys.argv[0])\n",
    "sett_mod = get_setting_module(setting_names,1)\n",
    "z_lens   = [s.z_lens   for s in sett_mod ]\n",
    "z_source = [s.z_source for s in sett_mod ]\n",
    "CombSett = combined_setting(comment,z_source,z_lens,filters,setting_names)\n",
    "pickle.dump(CombSett,open(str(save_dir)+\"/combined_setting.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We need to sample it for the plot \n",
    "if not KDE and mcmc:\n",
    "    from statistical_tools import *\n",
    "    from emcee import EnsembleSampler\n",
    "    from multiprocessing import cpu_count\n",
    "    mcmc_init_pos,mcmc_sigma = estimate_for_mcmc(Combined_PDF,Combined_bins)\n",
    "    #mcmc_sampling = sampler(mcmc_init_pos,prob=Combined_PDF,bins=Combined_bins,mcmc_simga=mcmc_sigma,mcmc_steps=int(1e6))\n",
    "    #mcmc_chain = mcmc_sampling[0]\n",
    "    def logP(pos):\n",
    "        prob_at_pos = get_prob_at_pos(pos,Combined_PDF,Combined_bins)\n",
    "        if prob_at_pos==0:\n",
    "            return -np.inf\n",
    "        return np.log(prob_at_pos)\n",
    "\n",
    "    nprocesses    = cpu_count()-1\n",
    "    nwalkers      = 42\n",
    "    init_sample   = sample_ball(mcmc_init_pos,mcmc_sigma,nwalkers)\n",
    "    pool          = MultiPool(processes=nprocesses) \n",
    "    emcee_mcmc    = EnsembleSampler(nwalkers,len(np.shape(Combined_PDF)), logP,pool=pool)\n",
    "    initial_state = sample_ball(mcmc_init_pos,mcmc_sigma,nwalkers)\n",
    "    emcee_mcmc.run_mcmc(initial_state= initial_state,nsteps=mcmc_steps)\n",
    "    mcmc_chain = emcee_mcmc.get_chain(discard=0, thin=1, flat=True)\n",
    "    with open(str(save_dir)+\"/mcmc_Df_chain.json\",\"w\") as f:\n",
    "        json.dump(np.array(mcmc_chain).tolist(),f)\n",
    "    plot = corner(mcmc_chain,bins=nbins,labels=[ p+\" [\\\"]\" for p in param_names], show_titles=True)\n",
    "    plot.savefig(str(save_dir)+\"/MCMC_multiplication_Df.png\")\n",
    "\n",
    "if not KDE:\n",
    "    from plotting_tools import plot_probability3D\n",
    "    plot = plot_probability3D(Combined_PDF,Combined_bins,labels=param_names,udm=\"\\\"\")\n",
    "    plot.savefig(str(save_dir)+\"/CombinedProbability.pdf\")\n",
    "else:\n",
    "    from plotting_tools import plot_probability3D_KDE\n",
    "    plot = plot_probability3D_KDE(Combined_PDF,Positions_KDE,labels=param_names,udm=\"\\\"\")\n",
    "    plot.savefig(str(save_dir)+\"/CombinedProbability_KDE.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result directory:\", str(save_dir))\n",
    "success(sys.argv[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
