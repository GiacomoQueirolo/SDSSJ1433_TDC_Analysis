{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling of the Quad SDSSJ144+6007 with HST image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copy from HST_HR.ipynb, modelling both _ws and not _ws setting file with the same program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lenstronomy.Data.imaging_data import ImageData\n",
    "from lenstronomy.Data.psf import PSF\n",
    "from lenstronomy.ImSim.image_model import ImageModel\n",
    "from lenstronomy.PointSource.point_source import PointSource\n",
    "from lenstronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.LightModel.light_model import LightModel\n",
    "from lenstronomy.Plots.model_plot import ModelPlot\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import importlib\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "import copy\n",
    "import pickle\n",
    "from argparse import ArgumentParser\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_res\n",
    "from image_manipulation import *\n",
    "import mag_remastered\n",
    "from input_data import init_kwrg_data,init_kwrg_psf,init_kwrg_numerics\n",
    "############################\n",
    "from tools import *\n",
    "present_program(sys.argv[0])\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser(description=\"Lens modelling program\")\n",
    "parser.add_argument('-rt','--run_type',type=int,dest=\"run_type\",default=0,help=\"Type of run: \\n \\\n",
    "                0 = standard, PSO_it = 400*rf   PSO_prt = 200*rf      MCMCr = 800*rf  MCMCb = 200*rf\\n \\\n",
    "                1 = append  MCMCr=800*rf\\n\\\n",
    "                2 = test run  PSO_it = 3   PSO_prt = 3   MCMCr = 2 MCMCb = 1\\n\\\n",
    "                3 = append test   MCMCr=3\\n\\\n",
    "                (PSO_it: PSO iterations, PSO_prt: PSO particles, MCMCr: MCMC run steps, MCMCb: MCMC burn in steps)\")\n",
    "parser.add_argument('-rf','--run_factor',type=float,dest=\"run_factor\",default=20.,help=\"Run factor to have longer run\")\n",
    "parser.add_argument('-tc','--threadCount',type=int,dest=\"threadCount\",default=150,help=\"Number of CPU threads for the MCMC parallelisation (max=160)\")\n",
    "parser.add_argument('SETTING_FILE',default=\"\",help=\"setting file to model\")\n",
    "\n",
    "args         = parser.parse_args()\n",
    "run_type     = args.run_type\n",
    "run_fact     = args.run_factor\n",
    "setting_name = args.SETTING_FILE.replace(\".py\",\"\").replace(\"settings/\",\"\")\n",
    "threadCount  = args.threadCount  \n",
    "RND = False #set a random start of the PSO\n",
    "n_run_cut = 50  # to re-implement\n",
    "#Model PSO/MCMC settings\n",
    "append_MC=False\n",
    "if run_type==0:\n",
    "    n_iterations=int(400*run_fact) #number of iteration of the PSO run\n",
    "    n_particles =int(200*run_fact) #number of particles in PSO run\n",
    "    n_run  = int(800*run_fact) #MCMC total steps \n",
    "    n_burn = int(200*run_fact) #MCMC burn in steps\n",
    "elif run_type ==1:\n",
    "    append_MC=True\n",
    "    n_run  = int(800*run_fact) #MCMC total steps \n",
    "elif run_type==2:\n",
    "    n_iterations=int(3) #number of iteration of the PSO run\n",
    "    n_particles =int(3) #number of particles in PSO run\n",
    "    n_run  = int(2) #MCMC total steps \n",
    "    n_burn = int(1) #MCMC burn in steps\n",
    "elif run_type==3:\n",
    "    append_MC   = True\n",
    "    n_run  = int(3) #MCMC total steps \n",
    "else:\n",
    "    raise RuntimeError(\"Give a valid run_type or implement it your own\")\n",
    "\n",
    "np.seterr(all=\"ignore\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backup_path   = \"backup_results\"\n",
    "savemcmc_path = get_savemcmcpath(setting_name,backup_path)\n",
    "savefig_path  = get_savefigpath(setting_name,backup_path) \n",
    "mkdir(savefig_path)\n",
    "mkdir(savemcmc_path)\n",
    "setting_path=find_setting_path(setting_name)\n",
    "os.system(\"cp \"+setting_path+\"/\"+setting_name+\".py \"+savefig_path+\".\") #we copy the setting file to that directory\n",
    "sys.path.append(setting_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b9ae28a7cd63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# A complicated way to import from the \"setting_name\" string all the values contained in that file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Determine a list of names to copy to the current name space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__all__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '-f'"
     ]
    }
   ],
   "source": [
    "setting_module = importlib.import_module(setting_name) \n",
    "setting = setting_module.setting()\n",
    "CP = check_if_CP(setting)\n",
    "WS = check_if_WS(setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CP:\n",
    "    print(\"WARNING: Considering the PEMD mass profile for the main lens\")\n",
    "if WS:\n",
    "    print(\"WARNING: this model DO NOT consider the source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WS and setting_name[-3:]!=\"_ws\":\n",
    "    os.system(\"cp \"+setting_dir+\"/\"+setting_name+\".py settings/\"+setting_name+\"_ws.py\") \n",
    "    def line_prepender(filename, line):\n",
    "        with open(filename, 'r+') as f:\n",
    "            content = f.read()\n",
    "            f.seek(0, 0)\n",
    "            f.write(line.rstrip('\\r\\n') + '\\n' + content)\n",
    "    line_prepender(setting_dir+\"/\"+setting_name+\"_ws.py\",\"#SIMPLE COPY FROM \"+setting_name+\".py\")\n",
    "    setting_name=setting_name+\"_ws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "print(\"Running: \",sys.argv[0])\n",
    "print(\"Machine: \",os.uname()[1]) \n",
    "print(\"Setting file:\", setting_name)\n",
    "print(\"Started the :\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "image_file   = setting.data_path+setting.image_name\n",
    "err_file     = setting.data_path+setting.err_name\n",
    "psf_file     = setting.data_path+setting.psf_name \n",
    "err_psf_file = setting.data_path+setting.err_psf\n",
    "\"\"\"\n",
    "\n",
    "##Printout of the results\n",
    "print_res = open(savefig_path+\"results.txt\",\"w\")\n",
    "print_res.write(\"Results for \"+setting_name+\" \\n\")\n",
    "print_res.write(\"#################################\\n\\n\")\n",
    "print_res.write(\"Date and time of start : \"+ dt_string+\"\\n\")\n",
    "print_res.write(\"Results obtained with \"+sys.argv[0]+\"\\n\")\n",
    "print_res.write(\"Setting file used settings/\"+setting_name+\"\\n\")\n",
    "print_res.write(\"Comments: \"+setting.comments+\"\\n\")\n",
    "print_res.write(\"append_MC: \"+str(append_MC)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"image = load_fits(image_file)\n",
    "plot_image(image,setting,savefig_path+\"/original_image.png\")\n",
    "numPix = image.shape[0]\n",
    "err_image = load_fits(err_file)\n",
    "# the masking procedure define the mask, subtract the eventual lens light profile,\n",
    "# plot the error and image masked and return the subtracted (unmasked) image and the mask\n",
    "mask = create_mask(image,setting)\n",
    "# Subtract lens light (if necessary)\n",
    "image_sub = subtract_light(image,setting)\n",
    "# Plot the subtracted and masked data image and error\n",
    "if setting.sub:\n",
    "    plot_image(image_sub*mask,setting,savefig_path+\"/image_sub_mask.png\")\n",
    "else:\n",
    "    plot_image(image_sub*mask,setting,savefig_path+\"/image_mask.png\")\n",
    "plot_image(err_image*mask,setting,savefig_path+\"/err_mask.png\",err_image=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"kwargs_data = { 'noise_map':   err_image,  # noise map\n",
    "                'ra_at_xy_0':  setting.ra_at_xy_0,  # RA  at (0,0) pixel\n",
    "                'dec_at_xy_0': setting.dec_at_xy_0, # DEC at (0,0) pixel \n",
    "                'ra_shift' :   0., #shifts the coordinate system with respect to 'ra_at_xy_0'    \n",
    "                'dec_shift':   0., #shifts the coordinate system with respect to 'dec_at_xy_0'    \n",
    "                'transform_pix2angle': setting.transform_pix2angle,#Mpix2coord,  \n",
    "                # matrix to translate shift in pixel in shift in relative RA/DEC (2x2 matrix). \n",
    "                # Make sure it's units are arcseconds or the angular units you want to model.\n",
    "                'image_data': image_sub  # 2d data vector\n",
    "              }\"\"\"\n",
    "kwargs_data,mask = init_kwrg_data(setting,saveplots=True,backup_path=backup_path,return_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"psf_image = load_fits(psf_file)\n",
    "\n",
    "if setting.pssf>1:\n",
    "    plot_image(psf_image,setting,savefig_path+\"/psf_supersampled.png\")\n",
    "else:\n",
    "    plot_image(psf_image,setting,savefig_path+\"/psf.png\")\n",
    "\n",
    "#We import the psf error image \n",
    "err_psf_image = load_fits(err_psf_file)\n",
    "err_psf_image = psf_correction(err_psf_image,setting)\n",
    "\n",
    "plot_image(err_psf_image,setting,savefig_path+\"/err_psf.png\",err_image=True)\n",
    "\n",
    "\n",
    "kwargs_psf = {'psf_type': \"PIXEL\", \n",
    "              'kernel_point_source':psf_image,\n",
    "              'point_source_supersampling_factor':setting.pssf,\n",
    "              'psf_error_map':err_psf_image}\"\"\"\n",
    "kwargs_psf = init_kwrg_psf(setting,saveplots=True,backup_path=backup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of profiles for the modelling\n",
    "# Lens (mass) profile with perturber and the Shear\n",
    "lens_model_list = ['SIE']\n",
    "if CP:\n",
    "    lens_model_list = ['PEMD']\n",
    "lens_model_list = [*lens_model_list,'SIS','SHEAR_GAMMA_PSI']\n",
    "\n",
    "# Lens light profile with perturber\n",
    "if setting.sub==False:\n",
    "    light_model_list = [\"SERSIC_ELLIPSE\", \"SERSIC\",\"UNIFORM\"]\n",
    "else:\n",
    "    light_model_list = [\"SERSIC\",\"UNIFORM\"]\n",
    "if hasattr(setting,\"no_pert\"):\n",
    "    if setting.no_pert==True:\n",
    "        light_model_list=[\"UNIFORM\"]\n",
    "else:\n",
    "    setting.no_pert=False \n",
    "# Source host gal\n",
    "if not WS:\n",
    "    source_model_list = ['SERSIC_ELLIPSE']\n",
    "\n",
    "# Source light model: point \n",
    "point_source_list = ['LENSED_POSITION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_params = {'lens_model':        setting.lens_params,\n",
    "                'point_source_model': setting.ps_params,\n",
    "                'lens_light_model':   setting.lens_light_params}\n",
    "if not WS:\n",
    "    kwargs_params['source_model'] =   setting.source_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for the PSO/MCMC runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_likelihood = {}\n",
    "kwargs_likelihood[\"check_matched_source_position\"]=True\n",
    "kwargs_likelihood[\"source_position_tolerance\"]=0.01\n",
    "kwargs_likelihood[\"force_no_add_image\"] = True \n",
    "kwargs_likelihood[\"check_positive_flux\"] = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_likelihood[\"image_likelihood_mask_list\"] =  [mask.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_model = {'lens_model_list': lens_model_list,\n",
    "                'lens_light_model_list': light_model_list,\n",
    "                'point_source_model_list': point_source_list,\n",
    "                'additional_images_list': [False], #list of bools (same length as point_source_type_list).\n",
    "                # If True, search for additional images of the same source is conducted.\n",
    "                 'fixed_magnification_list': setting.fixed_mag,  # list of bools (same length as point_source_type_list).\n",
    "                #If True, magnification ratio of point sources is fixed to the one given by the lens model \n",
    "                }\n",
    "if not WS:\n",
    "    kwargs_model['source_light_model_list'] = source_model_list\n",
    "\n",
    "kwargs_numerics = init_kwrg_numerics(setting)\n",
    "multi_band_list = [[kwargs_data, kwargs_psf, kwargs_numerics]]\n",
    "# if you have multiple  bands to be modeled simultaneously, you can append them to the mutli_band_list\n",
    "kwargs_data_joint = {'multi_band_list': multi_band_list, \n",
    "                     'multi_band_type': 'multi-linear'  \n",
    "                     # 'multi-linear': every imaging band has independent solutions of the surface brightness, \n",
    "                     #'joint-linear': there is one joint solution of the linear coefficients \\\n",
    "                     # demanded across the bands.\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if setting.sub ==False:\n",
    "    joint_lens_with_light=[[0,0,[\"center_x\",\"center_y\"]],[1,1,[\"center_x\",\"center_y\"]]]\n",
    "else:\n",
    "    joint_lens_with_light=[[0,1,[\"center_x\",\"center_y\"]]]\n",
    "if setting.no_pert:\n",
    "    joint_lens_with_light=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_constraints = {'num_point_source_list': [4], \n",
    "                      'solver_type': 'NONE',\n",
    "                      'joint_lens_with_light':joint_lens_with_light}\n",
    "if not WS:\n",
    "    kwargs_constraints['joint_source_with_point_source'] = [[0, 0]]\n",
    "                     \n",
    "#  'joint_lens_with_light': list [[i_light, k_lens, ['param_name1', 'param_name2', ...]], [...], ...],\n",
    "#   joint parameter between lens model and lens light model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if append_MC :\n",
    "    mcmc_file_name = savemcmc_path+setting_name.replace(\"settings\",\"mcmc_smpl\")+\".json\"\n",
    "    with open(mcmc_file_name, 'r') as f:\n",
    "        mc_init_sample= np.array(json.load(f))\n",
    "    try:\n",
    "        mcmc_logL_file_name = savemcmc_path+setting_name.replace(\"settings\",\"mcmc_logL\")+\".json\"\n",
    "        with open(mcmc_logL_file_name, 'r') as f:\n",
    "            mc_init_logL= np.array(json.load(f))\n",
    "    except:\n",
    "        mc_init_logL= np.array([])\n",
    "else:\n",
    "    mc_init_sample = None\n",
    "    mc_init_logL= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to solve the \"OSError: [Errno 24] Too many open files\" by deleting the \n",
    "# n_run_cut implementation\n",
    "from my_lenstronomy.my_fitting_sequence import MyFittingSequence  # ONLY IMPORT IT HERE OR IT BREAK THE CODE\n",
    "\n",
    "fitting_seq = MyFittingSequence(kwargs_data_joint, kwargs_model, kwargs_constraints,\\\n",
    "                              kwargs_likelihood, kwargs_params)\n",
    "if not append_MC:\n",
    "    fitting_kwargs_list = [['MY_PSO', {'sigma_scale': 1., 'n_particles': n_particles, \n",
    "                                       'n_iterations': n_iterations,\"path\":savemcmc_path}]]\n",
    "else:\n",
    "    fitting_kwargs_list = []\n",
    "    n_burn=0\n",
    "if RND == False:\n",
    "    np.random.seed(3)\n",
    "\n",
    "\n",
    "fitting_kwargs_list.append(['MCMC', {'n_burn': n_burn, 'n_run': n_run, 'walkerRatio': 10, 'sigma_scale': .1,\\\n",
    "                                     \"threadCount\":threadCount, 'init_samples':mc_init_sample}])\n",
    "# First chain_list with only the PSO, the burn_in sequence and the first n_run_cut\n",
    "chain_list = fitting_seq.fit_sequence(fitting_kwargs_list) \n",
    "sampler_type, mc_init_sample_i, param_mcmc, mc_init_logL_i  = chain_list[-1]\n",
    "#append the previous results\n",
    "if append_MC:\n",
    "    mc_init_sample = np.array([*mc_init_sample,*mc_init_sample_i])\n",
    "    mc_init_logL   = np.array([*mc_init_logL,*mc_init_logL_i])\n",
    "else:\n",
    "    mc_init_sample = mc_init_sample_i\n",
    "    mc_init_logL   = mc_init_logL_i\n",
    "\n",
    "# save here chain_list results\n",
    "save_json(setting_name,mc_init_sample,\"mcmc_smpl\",backup_path=backup_path)\n",
    "save_json(setting_name,mc_init_logL,\"mcmc_logL\",backup_path=backup_path)\n",
    "if \"PSO\" in chain_list[0][0]:\n",
    "    save_json(setting_name,chain_list[0],\"pso\",backup_path=backup_path)\n",
    "\n",
    "kwargs_result   = fitting_seq.best_fit()\n",
    "param_file_name = savemcmc_path+setting_name.replace(\"settings\",\"mcmc_prm\")+\".dat\"\n",
    "with open(param_file_name, 'w+') as param_file:\n",
    "    for i in range(len(param_mcmc)):\n",
    "        param_file.writelines(param_mcmc[i]+\",\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct mcmc chain\n",
    "kw_mcmc        = get_res.get_mcmc(setting_name,backup_path)\n",
    "chain_list[-1] = ['MCMC',kw_mcmc[\"mcmc_smpl\"],kw_mcmc[\"mcmc_prm\"],kw_mcmc[\"mcmc_logL\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res.write(\"kwargs_model:\"+str(kwargs_model)+\"\\n\")\n",
    "print_res.write(\"kwargs_numerics:\"+str(kwargs_numerics)+\"\\n\")\n",
    "print_res.write(\"kwargs_constraints:\"+str(kwargs_constraints)+\"\\n\")\n",
    "del kwargs_likelihood[\"image_likelihood_mask_list\"]\n",
    "print_res.write(\"kwargs_likelihood:\"+str(kwargs_likelihood)+\"\\n\")\n",
    "if run_type%1:\n",
    "    print_res.write(\"PSO particles: \"+str(n_particles)+\"\\n\")\n",
    "    print_res.write(\"PSO run steps: \"+str(n_iterations)+\"\\n\")\n",
    "print_res.write(\"MCMC run steps: \"+str(n_run)+\"\\n\")\n",
    "print_res.write(\"MCMC burn in steps: \"+str(n_burn)+\"\\n\")\n",
    "print_res.write(\"number of non-linear parameters in the MCMC process: \"+ str(len(param_mcmc))+\"\\n\")\n",
    "print_res.write(\"parameters in order: \"+str(param_mcmc)+\"\\n\")\n",
    "print_res.write(\"number of evaluations in the MCMC process: \"+str(np.shape(chain_list[-1][1])[0])+\"\\n\")\n",
    "print_res.write(\"#################################\\n\")\n",
    "\n",
    "##Printout of the results with errors\n",
    "\n",
    "kwargs_sigma_upper={}\n",
    "kwargs_sigma_lower={}\n",
    "n_ra=0\n",
    "n_dec=0\n",
    "sampler_type, samples_mcmc, param_mcmc, dist_mcmc  = chain_list[-1]\n",
    "for i in range(len(param_mcmc)):\n",
    "    val_min, val, val_max = corner.quantile(samples_mcmc[:,i],q=[0.16, 0.5, 0.84])\n",
    "    sig_min = np.abs(val_min-val)\n",
    "    sig_max = val_max - val\n",
    "    sig_ref = np.min([sig_max,sig_min])\n",
    "    n_exp = np.log10(1/sig_ref)\n",
    "    fact=pow(10,int(n_exp)+2)\n",
    "    if sig_min==sig_max:\n",
    "        print_res.write(param_mcmc[i]+\"  \" +str(np.trunc(np.array(val)*fact)/fact)+\\\n",
    "                        \" +- \"+str(np.trunc(np.array(sig_max)*fact)/fact)+\"\\n\")\n",
    "    else:\n",
    "        print_res.write(param_mcmc[i]+\" \" +str(np.trunc(np.array(val)*fact)/fact)+\\\n",
    "                        \" - \"+str(np.trunc(np.array(sig_min)*fact)/fact)+\\\n",
    "                        \" + \"+str(np.trunc(np.array(sig_max)*fact)/fact)+\"\\n\")\n",
    "    if param_mcmc[i]!=\"ra_image\" and param_mcmc[i]!=\"dec_image\":\n",
    "        kwargs_sigma_lower[param_mcmc[i]]=sig_min\n",
    "        kwargs_sigma_upper[param_mcmc[i]]=sig_max\n",
    "\n",
    "    elif param_mcmc[i]==\"ra_image\":\n",
    "        kwargs_sigma_lower[\"ra_image_\"+str(n_ra)]=sig_min\n",
    "        kwargs_sigma_upper[\"ra_image_\"+str(n_ra)]=sig_max            \n",
    "        n_ra+=1\n",
    "    else:\n",
    "        kwargs_sigma_lower[\"dec_image_\"+str(n_dec)]=sig_min\n",
    "        kwargs_sigma_upper[\"dec_image_\"+str(n_dec)]=sig_max            \n",
    "        n_dec+=1\n",
    "print_res.write(\"\\n#################################\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the obtained models\n",
    "v_min,v_max     = setting.v_min,setting.v_max\n",
    "res_min,res_max = setting.res_min,setting.res_max\n",
    "\n",
    "modelPlot = ModelPlot(multi_band_list, kwargs_model, kwargs_result,likelihood_mask_list=[mask.tolist()],\\\n",
    "                      arrow_size=0.02, cmap_string=\"gist_heat\")\n",
    "\n",
    "if not WS:\n",
    "    from plotting_tools import plot_model    as PM\n",
    "else:\n",
    "    from plotting_tools import plot_model_WS as PM\n",
    "    \n",
    "PM(modelPlot,savefig_path,v_min,v_max,res_min,res_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printout of all results after obtaining the amplitude\n",
    "with open(savefig_path+\"/read_results.data\",\"wb\") as f:\n",
    "        pickle.dump(kwargs_result, f)\n",
    "        \n",
    "print_res.write(\"kwargs_results:\\n\")\n",
    "for res in kwargs_result:\n",
    "    len_res = len(kwargs_result[str(res)])\n",
    "    for i in range(len_res):\n",
    "            print_res.write(str(res)+\" \"+str(i)+\"\\n\")\n",
    "            for j in kwargs_result[str(res)][i]:\n",
    "                print_res.write(str(j)+\": \"+str(np.trunc(np.array(kwargs_result[str(res)][i][str(j)])*1e4)/1e4)+\"\\n\")\n",
    "            print_res.write(\"\\n\")\n",
    "    print_res.write(\"\\n\")\n",
    "\n",
    "print_res.write(\"\\n#################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logL   = modelPlot._imageModel.likelihood_data_given_model(source_marg=False, linear_prior=None, **kwargs_result)\n",
    "n_data = modelPlot._imageModel.num_data_evaluate\n",
    "print_res.write(str(-logL * 2 / n_data)+' reduced X^2 of all evaluated imaging data combined\\n')\n",
    "print_res.write(\"################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalised plot\n",
    "f, axes = plt.subplots(figsize=(10,7))\n",
    "modelPlot.normalized_residual_plot(ax=axes,v_min=res_min, v_max=res_max)\n",
    "plt.savefig(savefig_path+\"normalised_residuals.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caustics\n",
    "f, axes = plt.subplots(figsize=(10,7))\n",
    "modelPlot.source_plot(ax=axes, deltaPix_source=0.01, numPix=1000, with_caustics=True)\n",
    "f.tight_layout()\n",
    "f.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0., hspace=0.05)\n",
    "plt.savefig(savefig_path+\"caustics.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(figsize=(10,7))\n",
    "modelPlot.decomposition_plot(ax=axes, text='Point source position', source_add=False, \\\n",
    "                lens_light_add=False, point_source_add=True, v_min=v_min, v_max=v_max)\n",
    "plt.savefig(savefig_path+\"point_source_position.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK_FR\n",
    "\n",
    "#Since the time is the same for all images (considering no time delay, or negligible), we can consider the \n",
    "# flux ratio to be amp_i/amp_max\n",
    "\n",
    "FR = mag_remastered.flux_ratio(setting,kwargs_result,kwargs_numerics,kwargs_data,\n",
    "               lens_model_list,light_model_list,point_source_list)\n",
    "ratio_name = [\"A/brightest\",\"C/brightest\",\"B/brightest\",\"D/brightest\"]\n",
    "print_res.write(\"Flux ratio for \"+setting.filter_name+\"\\n\")\n",
    "\n",
    "for i,FR_i in enumerate(FR):\n",
    "    print_res.write(\"Flux ratio:\"+str(FR_i)+\" \"+str(ratio_name[i])+\"\\n\")    \n",
    "print_res.write(\"########################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results of the MCMC chain\n",
    "\n",
    "i=0\n",
    "increment= 4\n",
    "samples_transposed = np.array(samples_mcmc).T\n",
    "\n",
    "n_sample = len (samples_mcmc)\n",
    "samples_mcmc_cut = samples_mcmc\n",
    "if not len(samples_mcmc) == 0:\n",
    "    n, num_param = np.shape(samples_mcmc_cut)\n",
    "    plot = corner.corner(np.array(samples_mcmc_cut[:,:]), labels=param_mcmc[:], show_titles=True)\n",
    "    plot.savefig(savefig_path+\"MCMC_posterior.png\")\n",
    "\n",
    "    #We implement the time delay posterior\n",
    "    #####################################\n",
    "    lensModel = LensModel(lens_model_list=lens_model_list, z_lens=setting.z_lens, z_source=setting.z_source)\n",
    "    #Note: the fermat potential is (should be, double check it) independent on the cosmology, \n",
    "    # while the time delay is\n",
    "    mcmc_new =[]\n",
    "    labels_new = [\"$\\phi_{Fermat}A$\", \"$\\phi_{Fermat}C$\",\"$\\phi_{Fermat}B$\" ,\"$\\phi_{Fermat}D$\",\"$\\Delta t_{A-C}$\", \"$\\Delta t_{A-B}$\", \"$\\Delta t_{A-D}$\"]\n",
    "\n",
    "    for i in range(len(samples_mcmc_cut)):\n",
    "        #MOD_PROD\n",
    "        try:\n",
    "            kwargs_result_i = setting.produce_kwargs_result(samples_mcmc,param_mcmc,i)\n",
    "        except NameError:\n",
    "            print(\"ERROR: The function setting.produce_kwargs_result is not implemented in \",setting_name,\".py file. \")\n",
    "            raise\n",
    "        x_image= kwargs_result_i[\"kwargs_ps\"][0][\"ra_image\"][0]\n",
    "        y_image= kwargs_result_i[\"kwargs_ps\"][0][\"dec_image\"][0]\n",
    "        fermat_potential = []\n",
    "        t_days=[]\n",
    "        for j in range(len(x_image)):\n",
    "            fermat_potential.append(lensModel.fermat_potential(x_image[j],y_image[j],kwargs_result_i[\"kwargs_lens\"]))\n",
    "            t_days.append(lensModel.arrival_time(x_image[j], y_image[j],  kwargs_result_i[\"kwargs_lens\"]))\n",
    "        mc_i = []\n",
    "        for j in range(len(fermat_potential)):\n",
    "            mc_i.append(fermat_potential[j])\n",
    "        dt=[t_days[0] - t_days[1], t_days[0] - t_days[2], t_days[0] - t_days[3]]\n",
    "        for j in range(len(dt)):\n",
    "            mc_i.append(dt[j])\n",
    "        mcmc_new.append(np.array(mc_i))\n",
    "    plot = corner.corner(np.array(mcmc_new), labels=labels_new, show_titles=True)\n",
    "    plot.savefig(savefig_path+\"MCMC_time_delay.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We save the time delay with the error measure\n",
    "print_res.write(\"\\n#################################\\n\")\n",
    "print_res.write(\"\\nTime delay and fermat potential with MCMC-derived error\\n\")\n",
    "kwargs_fermat={}\n",
    "for i in range(len(labels_new)):\n",
    "    val_min, val, val_max = corner.quantile(np.array(mcmc_new)[:,i],q=[0.16, 0.5, 0.84])\n",
    "    sig_min = np.abs(val_min-val)\n",
    "    sig_max = val_max - val\n",
    "    sig_ref = np.min([sig_max,sig_min])\n",
    "    n_exp = np.log10(1/sig_ref)\n",
    "    fact=pow(10,int(n_exp)+2)\n",
    "    if sig_min==sig_max:\n",
    "        print_res.write(labels_new[i]+\"  \" +str(np.trunc(np.array(val)*fact)/fact)+\\\n",
    "                        \" +- \"+str(np.trunc(np.array(sig_max)*fact)/fact)+\"\\n\")\n",
    "    else:\n",
    "        print_res.write(labels_new[i]+\" \" +str(np.trunc(np.array(val)*fact)/fact)+\\\n",
    "                        \" - \"+str(np.trunc(np.array(sig_min)*fact)/fact)+\\\n",
    "                        \" + \"+str(np.trunc(np.array(sig_max)*fact)/fact)+\"\\n\")\n",
    "    kwargs_fermat[labels_new[i]]=(val,sig_min,sig_max)\n",
    "print_res.write(\"\\n#################################\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time delay\n",
    "print_res.write(\"\\n########################\\n\")\n",
    "print_res.write(\"Time delay\\nWe are considering the standard cosmology of astropy\\n\")\n",
    "\n",
    "# if we consider the new image we convert the pix_coord of the objects\n",
    "# and after that obtain the angle via pix_scale\n",
    "\n",
    "lensModel = LensModel(lens_model_list=lens_model_list, z_lens=setting.z_lens, z_source=setting.z_source)\n",
    "\n",
    "# here are the predicted time delays in units of days\n",
    "x_image= kwargs_result[\"kwargs_ps\"][0][\"ra_image\"]\n",
    "y_image= kwargs_result[\"kwargs_ps\"][0][\"dec_image\"]\n",
    "t_days = lensModel.arrival_time(x_image, y_image, kwargs_result[\"kwargs_lens\"])\n",
    "#This are \"absolute time\", useless since we cannot measure them\n",
    "\n",
    "# here are the predicted time delays in units of days\n",
    "t_days =[]\n",
    "k=0\n",
    "for x in x_image:\n",
    "    t_days.append(lensModel.arrival_time(x, y_image[k],  kwargs_result[\"kwargs_lens\"]))\n",
    "    k+=1\n",
    "    \n",
    "print_res.write ('time delays: '+ str(t_days[0] - t_days[1])+\" \"+str(t_days[0] - t_days[2])+\"  \"+\\\n",
    "                  str(t_days[0] - t_days[3])+\"\\n\")\n",
    "\n",
    "print_res.write (\"Between images 0-1, 0-2, 0-3 with coord x:\"+str(x_image)+\" \\nand coord y\"+str(y_image)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOD_SOURCE \n",
    "from source_pos import get_source_pos_MCMC\n",
    "kwargs_source_out,str_src = get_source_pos_MCMC(setting,svfg=True)\n",
    "print_res.write(str_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing result.txt\n",
    "print_res.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I save the kwargs result in a pickly, readable way\n",
    "def pickle_results(res,name):\n",
    "    if not \".data\" in name:\n",
    "        name+=\".data\"\n",
    "    with open(savefig_path+name,\"wb\") as f:\n",
    "        pickle.dump(res, f)\n",
    "last_kw = {\"read_results\":kwargs_result,\n",
    "           \"read_sigma_up\":kwargs_sigma_upper,\n",
    "           \"read_sigma_low\":kwargs_sigma_lower,\n",
    "           \"read_fermat\":kwargs_fermat,\n",
    "           \"read_source\":kwargs_source_out,\n",
    "           \"FR\":FR}\n",
    "for nm in last_kw:\n",
    "    pickle_results(last_kw[nm],nm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'setting_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-002ce0e8b5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlast_comand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-002ce0e8b5a7>\u001b[0m in \u001b[0;36mlast_comand\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlast_comand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mstr_com\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msetting_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_com\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_com\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'setting_name' is not defined"
     ]
    }
   ],
   "source": [
    "# add some final commands\n",
    "\n",
    "import last_comands\n",
    "    \n",
    "for i in last_comands.progs:\n",
    "    last_comands.last_comand(setting_name, i,log=True) \n",
    "    \n",
    "    \n",
    "from check_success import check_success\n",
    "check_success(setting_name,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success(sys.argv[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
