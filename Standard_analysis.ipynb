{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Mod from Notes 19th october: we consider a spline ml and see the difference with the only polynomial case \n",
    "#-> Expected: larger error distribution, smaller systematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycs3.gen.lc_func\n",
    "import pycs3.spl.topopt\n",
    "import pycs3.gen.mrg\n",
    "import pycs3.gen.splml\n",
    "import pycs3.gen.stat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import normal as norm\n",
    "from numpy.random import uniform as unif\n",
    "import os, sys\n",
    "import argparse as ap\n",
    "from copy import copy\n",
    "import json\n",
    "import pickle\n",
    "import importlib\n",
    "import pathlib as pth\n",
    "import multiprocessing \n",
    "import time\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from corner import quantile\n",
    "#from red_chi import red_chi, get_chi_red\n",
    "from stnd_red_chi import get_chi_red\n",
    "from plot_distrib import plot_result_dt_single\n",
    "#from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "from tools import *\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to have standardised plots\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['font.size']= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processes= multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_analysis(config,verbose=False):\n",
    "    \n",
    "    lcs = config.get_lcs() \n",
    "    \n",
    "    if config.maskA:\n",
    "        lcs=mask_A_peak(lcs)\n",
    "        \n",
    "    if verbose:\n",
    "       # Useful info\n",
    "        lc_i = lcs[0]\n",
    "        print ( \"Lenght of observation campaign: \",(max(lc_i.getjds())-min(lc_i.getjds())),\" days\")\n",
    "        print ( \"N* of nights of observation campaign: \",len(lc_i.getjds()) ,\" days\")\n",
    "    \n",
    "    orig_shift_time = config.timeshifts\n",
    "    orig_shift_mag  = set_orig_magshift(lcs)\n",
    "    \n",
    "    savefig_path=pth.Path(config.analysis_directory)\n",
    "    mkdir(savefig_path)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Starting nested loop\")\n",
    "    for a, knt in enumerate(config.knotstep_marg): #knotstep of the intr.spline\n",
    "        if verbose:\n",
    "            print(\"analysing intrinsic knot \",knt)\n",
    "        saveknt_path = savefig_path/str(\"analysis_kn\"+str(knt))\n",
    "        mkdir(savefig_path)        \n",
    "        for mlt_i, mltype_i in enumerate(config.mltype): #ml type\n",
    "            if verbose:\n",
    "                print(\"Considering ml type \",mltype_i)\n",
    "\n",
    "            for mlc_i,ml_config in enumerate(config.ml_config[mlt_i]):\n",
    "                if verbose:\n",
    "                    print(\"Considering ml config \", ml_config)\n",
    "                mllist_name,mlfp = ml_config \n",
    "                # note: mlfp is for polyml the n* of Free Parameters ofthe polynomial, or the \n",
    "                kwargs_mc = {\"knst_list\":config.knotstep, \"nit\":config.nit,\n",
    "                 \"dt_range\":config.tsrand,\"mc_res\":config.mc_res}\n",
    "                kwargs_ml = {\"mltype\":mltype_i,\"mllist_name\":mllist_name}\n",
    "\n",
    "                if mltype_i==\"polyml\":\n",
    "                    mlfp_str=\"_mlfp_\"+str(mlfp)\n",
    "                    kwargs_ml[\"mlfp\"] = mlfp\n",
    "                else:\n",
    "                    if config.forcen:\n",
    "                        mlfp_str=\"_nmlspl_\"+str(mlfp)\n",
    "                    else:\n",
    "                        mlfp_str=\"_knstml_\"+str(mlfp)\n",
    "                    kwargs_ml[\"forcen\"] = config.forcen\n",
    "                    kwargs_ml[\"nmlspl\"] = mlfp\n",
    "                kwargs_mc.update(kwargs_ml)\n",
    "                saveml_path = saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str)\n",
    "                savesplines_path =saveml_path/\"splines/\"\n",
    "\n",
    "                #mkdir\n",
    "                mkdir(saveml_path)\n",
    "                saveml_path = str(saveml_path)+\"/\"\n",
    "                mkdir(savesplines_path)\n",
    "                savesplines_path = str(savesplines_path)+\"/\"\n",
    "                print(\"Saving results in: \"+saveml_path)\n",
    "\n",
    "                \n",
    "                with open(saveml_path+\"/kwargs_mc.data\",\"wb\") as f:\n",
    "                    pickle.dump(kwargs_mc,f)\n",
    "                    \n",
    "                data_vct= {\"mc_res\":config.mc_res,\"tsrand\":config.tsrand,\"lcs\":lcs,\\\n",
    "                           \"savesplines_path\":savesplines_path,\\\n",
    "                           \"orig_shift_mag\":orig_shift_mag,\\\n",
    "                           \"orig_shift_time\":orig_shift_time,\"knt\":knt,\\\n",
    "                           \"mlparams\":kwargs_ml}\n",
    "                begin = time.time()\n",
    "                if verbose:\n",
    "                    print(\"Starting time \",begin)\n",
    "                if __name__ == '__main__':\n",
    "                    with multiprocessing.Pool(n_processes) as p:\n",
    "                        timedelays, in_time_shift, in_mag_shift, chi_red, splines, residuals =\\\n",
    "                        zip(*p.map(partial(single_analysis,**data_vct),range(config.mc_res)),range(config.mc_res))\n",
    "                end = time.time()\n",
    "                #I don't know why but this might be necessary\n",
    "                if timedelays[-1]==0:\n",
    "                    if len(timedelays)==config.mc_res+1:\n",
    "                        timedelays = timedelays[:-1]\n",
    "                        in_time_shift = in_time_shift[:-1]\n",
    "                        in_mag_shift = in_mag_shift[:-1]\n",
    "                        chi_red = chi_red[:-1]\n",
    "                        splines = splines[:-1]\n",
    "                        residuals = residuals[:-1]\n",
    "                if verbose:\n",
    "                    print(\"End time \",end)\n",
    "                    print(\"Done with multiprocessing in t=\",(end-begin)/3600.,\" h\\n\")\n",
    "    \n",
    "                with open(saveml_path+\"/td.data\", 'wb') as f:\n",
    "                    pickle.dump(timedelays, f)\n",
    "                with open(saveml_path+\"/in_time_shift.data\", 'wb') as f:\n",
    "                    pickle.dump(in_time_shift, f)\n",
    "                with open(saveml_path+\"/in_mag_shift.data\", 'wb') as f:\n",
    "                    pickle.dump(in_mag_shift, f)\n",
    "                with open(saveml_path+\"/chi_red.data\", 'wb') as f:\n",
    "                    pickle.dump(chi_red, f)\n",
    "                with open(saveml_path+\"/splines.data\", 'wb') as f:\n",
    "                    pickle.dump(splines, f)\n",
    "                with open(saveml_path+\"/resid.data\", 'wb') as f:\n",
    "                    pickle.dump(residuals, f)\n",
    "                ########## Plot the resulting time delay distribution #############\n",
    "                name = str(config.combkw[a][mlt_i][mlc_i]).replace(\"spl1_\",\"\")\n",
    "                distr = np.transpose(timedelays)\n",
    "                plot_result_dt_single(distr,name,saveml_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary functions:\n",
    "def set_orig_magshift(lcs):\n",
    "    mag = []\n",
    "    for i in range(len(lcs)):\n",
    "        mg = lcs[i].getmags()\n",
    "        mg_er = lcs[i].getmagerrs()\n",
    "        mg_av = 0\n",
    "        mg_err_sq=0\n",
    "        for j in range( len(mg)):\n",
    "            mg_av += mg[j]/(mg_er[j]**2)\n",
    "            mg_err_sq+=1/(mg_er[j]**2)\n",
    "        mag.append(mg_av/mg_err_sq) \n",
    "    true_shift_mag =-( np.array(mag) - mag[0])\n",
    "    return true_shift_mag.tolist()\n",
    "def mask_A_peak(lcs):\n",
    "    lc=lcs[0]\n",
    "    #MOD_MODERATE_MASK\n",
    "    for i in [71,73,74,75, 83,84,85,86,87]:\n",
    "        lc.magerrs[i]*=30\n",
    "    return lcs\n",
    "\n",
    "#@jit\n",
    "def single_analysis(mc_i,mc_res,tsrand,lcs,savesplines_path,orig_shift_mag,orig_shift_time,knt,mlparams):\n",
    "    if mc_i%(20/mc_res)==0:\n",
    "        print(\"Iteration \"+str(mc_i+1)+\" of \"+str(mc_res)+\" (\"+str(np.round((mc_i+1)*100/mc_res,3))+\"%)\")\n",
    "    \n",
    "    np.random.seed(mc_i)\n",
    "    \n",
    "    sig_mag =[np.median(lci.getmagerrs()) for lci in lcs]\n",
    "\n",
    "    \n",
    "    spl = config.spl1\n",
    "    #this avoid that bad choices of parameters make the spline fitting fail\n",
    "    while True:\n",
    "        # initialise mag, dt and lightcurves:\n",
    "        shift_mag  = copy(orig_shift_mag)    \n",
    "        shift_time = copy(orig_shift_time)  \n",
    "        for l in lcs:\n",
    "            l.resetshifts() \n",
    "        # random variation of initial guesses\n",
    "        for j in range(len(lcs)):\n",
    "            dt_unif = unif(-tsrand,tsrand)\n",
    "            shift_time[j] = shift_time[j] + dt_unif\n",
    "\n",
    "            dmag_norm    = norm(0,sig_mag[j] )\n",
    "            shift_mag[j] = shift_mag[j] + dmag_norm \n",
    "\n",
    "        # we had an initial guess of the time shift and mag shift\n",
    "        pycs3.gen.lc_func.applyshifts(lcs, shift_time, shift_mag)\n",
    "        \n",
    "        # consider the microlensing for lc B, C and D\n",
    "        config.attachml(lcs,mlparams) \n",
    "        try: \n",
    "            spline = spl(lcs,kn=knt)\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    l = pycs3.gen.lc_func.getnicetimedelays(lcs) \n",
    "    all_dt=[]\n",
    "    for j in (l.split(\" \")):\n",
    "        if '\\n' in j or j==l.split(\" \")[-1]:\n",
    "            all_dt.append(-float(j.split(\"\\n\")[0]))  \n",
    "    timedelay_ab,timedelay_ac,timedelay_bc = all_dt[:3]\n",
    "    \n",
    "    # Auxiliary info\n",
    "    # so we can see the spline and ml when secondary peaks appears\n",
    "    if np.any([np.abs(all_dt[k] +orig_shift_time[1:][k])>7 for k in range(len(all_dt[:2]))]):\n",
    "        str_dt = str(np.round(all_dt,0)).replace(\" \",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\".\",\"_\")[:-1]\n",
    "        file_lcs_bad =str(savesplines_path)+\"/large_ddt_\"+str(mc_i+1)+\".data\"\n",
    "        with open(file_lcs_bad,\"wb\") as f:\n",
    "            pickle.dump([*lcs,spline,all_dt,mlparams],f)\n",
    "            \n",
    "    #initial time and mag shifts\n",
    "    in_time_shift = shift_time\n",
    "    in_mag_shift  = [lc.magshift for lc in lcs]\n",
    "    \n",
    "    # FR study - 16th March\n",
    "    # consider only the polynomial case for now\n",
    "    if mlparams[\"mltype\"]==\"polyml\":\n",
    "        mllist = config.get_mllist(mlparams[\"mllist_name\"] )\n",
    "        mag_ml_shift = []\n",
    "        for j in range(len(lcs)):\n",
    "            if j in mllist:\n",
    "                mag_ml_shift.append(lcs[j].ml.getfreeparams()[1])\n",
    "            else:\n",
    "                mag_ml_shift.append(0)\n",
    "        tot_mag_shift = np.array(mag_ml_shift) + np.array(in_mag_shift) #to be ADDED to the mag of the lcs in order to shift them\n",
    "        with open(str(savesplines_path).replace(\"splines/\",\"\")+\"/tot_mag_shift.data\",\"wb\") as f:\n",
    "            pickle.dump(tot_mag_shift)\n",
    "    \n",
    "    #residuals and chired\n",
    "    residual = pycs3.gen.stat.subtract(lcs,spline)\n",
    "    chi_red  = get_chi_red(spline,mlparams,nl_lc=len(lcs))\n",
    "    # we save an example of spline\n",
    "    if mc_i==0: \n",
    "        pycs3.gen.lc_func.display(lcs,[spline],nicefont=True,showdelays=True,\n",
    "                    filename=savesplines_path+\"fit.png\")\n",
    "    \n",
    "    return [timedelay_ab,timedelay_ac,timedelay_bc],\\\n",
    "            in_time_shift,in_mag_shift, chi_red, spline, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ap.ArgumentParser(prog=\"python {}\".format(os.path.basename(__file__)),\n",
    "                               description=\"My analysis\",\n",
    "                               formatter_class=ap.RawTextHelpFormatter)\n",
    "    help_lensname = \"name of the lens to process\"\n",
    "    help_dataname = \"name of the data set to process\"\n",
    "    parser.add_argument(dest='lensname', type=str,\n",
    "                        metavar='lens_name', action='store',\n",
    "                        help=help_lensname)\n",
    "    parser.add_argument(dest='dataname', type=str,\n",
    "                        metavar='dataname', action='store',\n",
    "                        help=help_dataname)\n",
    "    parser.add_argument('-v','--verbose',help=\"Verbosity\",\n",
    "                        dest=\"verbose\", \n",
    "                        default=False,action=\"store_true\")\n",
    "    args      = parser.parse_args()\n",
    "    lensname  = args.lensname\n",
    "    dataname  = args.dataname\n",
    "    verbose   = args.verbose\n",
    "    name_prog = sys.argv[0]\n",
    "    present_program(name_prog)\n",
    "\n",
    "    sys.path.append(\"myconfig/\")\n",
    "    config_file = \"myconfig_\" + lensname + \"_\" + dataname\n",
    "    config = importlib.import_module(config_file)\n",
    "    mkdir(config.lens_directory)\n",
    "    \n",
    "    dt_string = time.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(\"Machine: \",os.uname()[1]) \n",
    "    print(\"Config file:\", config_file)\n",
    "    print(\"Started the :\", dt_string)\n",
    "    print(\"#########################\")\n",
    "    standard_analysis(config,verbose=verbose)\n",
    "    ####\n",
    "    comand = \"python observed_FR.py \"+lensname+\" \"+dataname+\" &> logs/log_FR_\"+lensname+\"_\"+dataname+\".log &\" \n",
    "    os.system(comand)\n",
    "    ####\n",
    "\n",
    "    success(name_prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
