{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from corner import quantile\n",
    "import matplotlib.pyplot as plt\n",
    "from pycs3.tdcomb.comb import Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error_main():\n",
    "    \n",
    "    def __init__(self,error_path=None):\n",
    "        self.error_path = error_path\n",
    "        if error_path is not None:\n",
    "            if os.path.exists(error_path):\n",
    "                self.create_error()   \n",
    "    def get_distr(self):\n",
    "        if hasattr(self,\"distr\"):\n",
    "            return self.distr\n",
    "        \n",
    "    def create_error(self):    \n",
    "        err_all = self.get_distr()\n",
    "\n",
    "        errors_up,errors_down,rnd,sys =[],[],[],[]\n",
    "        tot=[]\n",
    "        for i in range(len(err_all)):\n",
    "            min_e,med_e,max_e = quantile(err_all[i],q=[0.16,0.5,0.84])\n",
    "            err_up,err_down = max_e-med_e,med_e-min_e\n",
    "            errors_up.append(err_up)\n",
    "            errors_down.append(err_down)\n",
    "            rnd.append((err_up+err_down)/2.)\n",
    "            sys.append(med_e)\n",
    "        #tot =  sqrt(rnd² +sys²)\n",
    "        ############################################################\n",
    "        #tot = [np.sqrt(rnd[i]**2 + sys[i]**2) for i in range(len(err_all))]\n",
    "        tot = sqrt_sum(rnd,sys)\n",
    "        ############################################################\n",
    "        self.err_up   = errors_up\n",
    "        self.err_down = errors_down\n",
    "        self.rnd = rnd\n",
    "        self.sys = sys\n",
    "        self.tot = tot\n",
    "        self.accuracy = np.mean(tot) #prob not needed anymore\n",
    "        \n",
    "class Error():\n",
    "    \n",
    "    def __init__(self,error_path=None):\n",
    "        self.error_path = error_path\n",
    "        if error_path is not None:\n",
    "            if os.path.exists(error_path):\n",
    "                self.create_error()\n",
    "        \n",
    "    def get_dt(self,meas_or_sim):\n",
    "        if self.error_path is None:\n",
    "            raise RuntimeError(\"Give me a path to the simulations results\")\n",
    "        list_file = os.listdir(path=self.error_path)\n",
    "        list_file = [list_file[i] for i in range(len(list_file)) if \"runresults.pkl\" in list_file[i]]\n",
    "        if len(list_file)==0:\n",
    "            raise RuntimeError(\"No resulting files in this directory: \"+str(self.error_path))\n",
    "        for i,file in enumerate(list_file):\n",
    "            rr = pkl.load(open(self.error_path+\"/\"+file,\"rb\"))\n",
    "            if meas_or_sim==\"meas\":\n",
    "                tsarr = rr.tsarray\n",
    "            elif meas_or_sim==\"sim\":\n",
    "                tsarr = rr.truetsarray\n",
    "            # MOD_DELTA\n",
    "            # do not consider tA,tB and tC, but DtAB,DtAC AND DtBC \n",
    "            # tsarr.shape = 20,3\n",
    "            tsarrT = tsarr.T # shape 3,20\n",
    "            new_tsarrT = np.array([tsarrT[1]-tsarrT[0],tsarrT[2]-tsarrT[0],tsarrT[2]-tsarrT[1]]) # AB,AC,BC: shape 3,20\n",
    "            new_tsarr = np.transpose(new_tsarrT) # shape 20,3 \n",
    "            if i==0:\n",
    "                dts = new_tsarr\n",
    "            else:\n",
    "                dts = np.vstack((dts,new_tsarr))\n",
    "        return np.transpose(dts) #shape: dim, n*steps\n",
    "\n",
    "    def get_meas_dt(self):\n",
    "        if hasattr(self,\"measdt\") is False:\n",
    "            self.measdt = self.get_dt(\"meas\")\n",
    "        self.labels_measdt = [\"AB\",\"AC\",\"BC\"]\n",
    "        return self.measdt\n",
    "    \n",
    "    def get_sim_dt(self):\n",
    "        if hasattr(self,\"simdt\") is False:\n",
    "            self.simdt = self.get_dt(\"sim\")\n",
    "        self.labels_simdt = [\"AB\",\"AC\",\"BC\"]\n",
    "        return self.simdt \n",
    "\n",
    "    def get_distr(self):\n",
    "        if hasattr(self,\"distr\"):\n",
    "            return self.distr\n",
    "        elif not hasattr(self,\"measdt\") and not hasattr(self,\"simdt\"):\n",
    "            self.meas = self.get_meas_dt()\n",
    "            self.sim  = self.get_sim_dt()\n",
    "        #print(\"Note:Error is defined as measured dt - simulated dt\")\n",
    "        distr = self.measdt - self.simdt\n",
    "        self.distr = distr\n",
    "        if self.labels_measdt==self.labels_simdt:\n",
    "            self.labels = self.labels_simdt\n",
    "        else:\n",
    "            raise RuntimeError(\"Check the labels/dimensions\")\n",
    "        return self.distr\n",
    "            \n",
    "    def create_error(self):    \n",
    "        err_all = self.get_distr()\n",
    "\n",
    "        errors_up,errors_down,rnd,sys =[],[],[],[]\n",
    "        tot=[]\n",
    "        for i in range(len(err_all)):\n",
    "            min_e,med_e,max_e = quantile(err_all[i],q=[0.16,0.5,0.84])\n",
    "            err_up,err_down = max_e-med_e,med_e-min_e\n",
    "            errors_up.append(err_up)\n",
    "            errors_down.append(err_down)\n",
    "            rnd.append((err_up+err_down)/2.)\n",
    "            sys.append(med_e)\n",
    "        #tot =  sqrt(rnd² +sys²)\n",
    "        ############################################################\n",
    "        #tot = [np.sqrt(rnd[i]**2 + sys[i]**2) for i in range(len(err_all))]\n",
    "        tot = sqrt_sum(rnd,sys)\n",
    "        ############################################################\n",
    "        self.err_up   = errors_up\n",
    "        self.err_down = errors_down\n",
    "        self.rnd = rnd\n",
    "        self.sys = sys\n",
    "        self.tot = tot\n",
    "        self.accuracy = np.mean(tot) #prob not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error_mag():\n",
    "    \n",
    "    def __init__(self,error_path=None):\n",
    "        self.error_path = error_path\n",
    "        if error_path is not None:\n",
    "            if os.path.exists(error_path):\n",
    "                self.create_error()\n",
    "        \n",
    "    def get_dmag(self,meas_or_sim):\n",
    "        if self.error_path is None:\n",
    "            raise RuntimeError(\"Give me a path to the simulations results\")\n",
    "        list_file = os.listdir(path=self.error_path)\n",
    "        list_file = [list_file[i] for i in range(len(list_file)) if \"runresults.pkl\" in list_file[i]]\n",
    "        if len(list_file)==0:\n",
    "            raise RuntimeError(\"No resulting files in this directory: \"+str(self.error_path))\n",
    "        for i,file in enumerate(list_file):\n",
    "            rr = pkl.load(open(self.error_path+\"/\"+file,\"rb\"))\n",
    "            if meas_or_sim==\"meas\":\n",
    "                magsarr = rr.magsarray\n",
    "                self.labels_measdmag = [\"AB\",\"AC\",\"BC\"]\n",
    "            elif meas_or_sim==\"sim\":\n",
    "                magsarr = rr.truemagsarray\n",
    "                self.labels_simdmag = [\"AB\",\"AC\",\"BC\"]\n",
    "            elif meas_or_sim==\"error\":\n",
    "                # error defined as dmag- simulated dmag\n",
    "                magsarr = rr.magsarray - rr.truemagsarray\n",
    "                self.labels = [\"AB\",\"AC\",\"BC\"]\n",
    "                self.labels_simdmag = [\"AB\",\"AC\",\"BC\"]\n",
    "                self.labels_measdmag = [\"AB\",\"AC\",\"BC\"]\n",
    "            # MOD_DELTA\n",
    "            # do not consider mA,mB and mC, but DmAB,DmAC AND DmBC \n",
    "            # magsarr.shape = 20,3\n",
    "            magsarrT = magsarr.T # shape 3,20\n",
    "            \n",
    "            Dmagsarr = np.array([magsarrT[1]-magsarrT[0],magsarrT[2]-magsarrT[0],magsarrT[2]-magsarrT[1]]) # AB,AC,BC: shape 3,20\n",
    "            #new_magsarr = np.transpose(new_magsarrT) # shape 20,3 \n",
    "            if i==0:\n",
    "                dms = Dmagsarr\n",
    "            else:\n",
    "                dms = np.hstack((dms,Dmagsarr))\n",
    "        return dms #shape: dim, n*steps\n",
    "\n",
    "    def get_meas_dmag(self):\n",
    "        if hasattr(self,\"measdmag\") is False:\n",
    "            self.measdmag = self.get_dmag(\"meas\")\n",
    "        return self.measdmag\n",
    "    \n",
    "    def get_sim_dmag(self):\n",
    "        if hasattr(self,\"simdmag\") is False:\n",
    "            self.simdmag = self.get_dmag(\"sim\")\n",
    "        return self.simdmag \n",
    "\n",
    "    def get_distr(self):\n",
    "        if hasattr(self,\"distr\"):\n",
    "            return self.distr\n",
    "        #print(\"Note:Error is defined as measured dmag - simulated dmag\")\n",
    "        distr = self.get_dmag(\"error\")#self.get_meas_dmag() - self.get_sim_dmag()\n",
    "        self.distr = distr\n",
    "        if self.labels_measdmag==self.labels_simdmag:\n",
    "            self.labels = self.labels_simdmag\n",
    "        else:\n",
    "            raise RuntimeError(\"Check the labels/dimensions\")\n",
    "        return self.distr\n",
    "            \n",
    "    def create_error(self):    \n",
    "        err_all = self.get_distr()\n",
    "\n",
    "        errors_up,errors_down,rnd,sys =[],[],[],[]\n",
    "        tot=[]\n",
    "        for i in range(len(err_all)):\n",
    "            min_e,med_e,max_e = quantile(err_all[i],q=[0.16,0.5,0.84])\n",
    "            err_up,err_down = max_e-med_e,med_e-min_e\n",
    "            errors_up.append(err_up)\n",
    "            errors_down.append(err_down)\n",
    "            rnd.append((err_up+err_down)/2.)\n",
    "            sys.append(med_e)\n",
    "        #tot =  sqrt(rnd² +sys²)\n",
    "        ############################################################\n",
    "        #tot = [np.sqrt(rnd[i]**2 + sys[i]**2) for i in range(len(err_all))]\n",
    "        tot = sqrt_sum(rnd,sys)\n",
    "        ############################################################\n",
    "        self.err_up   = errors_up\n",
    "        self.err_down = errors_down\n",
    "        self.rnd = rnd\n",
    "        self.sys = sys\n",
    "        self.tot = tot\n",
    "        self.accuracy = np.mean(tot) #prob not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group():\n",
    "    def __init__(self,error=None,data_distr=None,labels=[\"AB\",\"AC\",\"BC\"],name=\"\", color=\"royalblue\"):\n",
    "        \n",
    "        self.data   = data_distr\n",
    "        self.labels = labels\n",
    "        self.name   = name\n",
    "        self.color  = color\n",
    "        \n",
    "        if self.data is not None:\n",
    "            self.results = np.mean(data_distr,axis=1)  # as usual median or mean? \n",
    "        else:\n",
    "            self.results = None\n",
    "        # All the error description are inherited by the Errorbar class\n",
    "        if error is not None:\n",
    "            if isinstance(error,(Error,Error_mag)):\n",
    "                self.error = error\n",
    "            elif type(error)==str : \n",
    "                error       = Error(error)\n",
    "                self.error  = error\n",
    "            else:\n",
    "                error_tmp       = Error(\"None\")\n",
    "                error_tmp.distr = error \n",
    "                self.error      = error_tmp\n",
    "            self.error.create_error()\n",
    "            # check that we have the right dataset:\n",
    "            if labels != getattr(self.error,\"labels\",labels):\n",
    "                raise RuntimeError(\"Check the labels/dimensions!\")\n",
    "            self.err_distr  = self.error.get_distr()\n",
    "            self.err_up     = self.error.err_up\n",
    "            self.err_down   = self.error.err_down\n",
    "            self.rnd_error  = self.error.rnd\n",
    "            self.sys_error  = self.error.sys\n",
    "            self.tot_error  = self.error.tot\n",
    "            self.accuracy   = self.error.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful functions \n",
    "        \n",
    "def getresults(data_path,name=\"\",error=None,color=\"royalblue\",labels=[\"AB\",\"AC\",\"BC\"]):\n",
    "    \"\"\"\n",
    "    ;My version of pycs3.tdcomb.comb.getresults; no need for CScontainer\n",
    "    \"\"\"\n",
    "\n",
    "    with open(str(data_path)+\"/td.data\",\"rb\") as f:\n",
    "        timedelays = pkl.load(f)\n",
    "    ###############################\n",
    "    #To better correct one day\n",
    "    if timedelays[-1]==0:\n",
    "        timedelays=timedelays[:-1]\n",
    "    ###############################\n",
    "    timedelays = np.transpose(timedelays) #shape now: lcs, mci\n",
    "    # create a Group out of them\n",
    "    group =  Group(data_distr=timedelays,error = error,name=name,labels=labels, color=color)\n",
    "    return group\n",
    "\n",
    "     \n",
    "def getresults_mag(data_path,name=\"\",error=None,color=\"royalblue\",labels=[\"AB\",\"AC\",\"BC\"]):\n",
    "    \"\"\"\n",
    "    ;same as getresults, but for mag\n",
    "    \"\"\"\n",
    "    if \"splml\" in str(data_path):\n",
    "        print(\"Not implemented for spline ML\")\n",
    "        return None\n",
    "    with open(str(data_path)+\"/dmags.data\",\"rb\") as f:\n",
    "        dmags = pkl.load(f)\n",
    "    dmags = np.transpose(dmags) #shape now: lcs, mci\n",
    "    # create a Group out of them\n",
    "    DmagBC = dmags[2] - dmags[1] # BC\n",
    "    Dmags  = dmags[1:]- dmags[0] #rel to A : AB,AC\n",
    "    Dmags  = np.append(Dmags,[DmagBC],0).tolist()\n",
    "    # now AB,AC,BC -> mostly to be consistent w. dt\n",
    "    group =  Group(data_distr=Dmags,error = error,name=name,labels=labels, color=color)\n",
    "    return group\n",
    "\n",
    "def sqrt_sum(a,b):\n",
    "    if np.shape(a)==():\n",
    "        return np.sqrt(a**2 + b**2)\n",
    "    else:\n",
    "        if len(a)!=len(b):\n",
    "            raise ValueError(\"Len of a and b must be equal, not: \"+str(len(a))+\" and \"+str(len(b)))\n",
    "        return np.array([np.sqrt(a[i]**2 + b[i]**2) for i in range(len(a))])\n",
    "    \n",
    "def sqrt_sum_list(list_ab):\n",
    "    if all([np.shape(ab)==() for ab in list_ab]):\n",
    "        return np.sqrt(np.sum([ab**2 for ab in list_ab]))\n",
    "    else:\n",
    "        if any([len(list_ab[0])!=len(ab) for ab in list_ab]):\n",
    "            raise ValueError(\"Len of each element must be equal\")\n",
    "        return np.array([np.sqrt(np.sum([ab[i]**2 for ab in list_ab])) for i in range(len(list_ab[0]))])\n",
    "    \n",
    "###############################\n",
    "# deprecated function, use method B\n",
    "def combine_group_list(list_G):\n",
    "    raise RuntimeWarning(\"Deprecated function, use methodB\")\n",
    "    for Gi in list_G[1:]:\n",
    "        if Gi.labels!=list_G[0].labels: #pragma: no cover\n",
    "            raise RuntimeError(\"Give me two groups of the same dataset!\")\n",
    "    #Following method A in Notes - 27th October \n",
    "    res_comb = np.mean([Gi.results for Gi in list_G],axis=0)                                          \n",
    "    err_comb = sqrt_sum_list([Gi.tot_error for Gi in list_G])/len(list_G)\n",
    "        \n",
    "    G_comb           = Group(error=None,labels=G1.labels)\n",
    "    G_comb.results   = res_comb\n",
    "    G_comb.tot_error = err_comb\n",
    "    \n",
    "    G_comb.color = \"black\"\n",
    "    G_comb.name  = \"Combined \"+str([Gi.name.replace(\"Combined \",\"\")+\" and \" for Gi in list_G])\n",
    "    return G_comb\n",
    "###############################\n",
    "\n",
    "def combine_group_list_methodB(list_G):\n",
    "    for Gi in list_G[1:]:\n",
    "        if Gi.labels!=list_G[0].labels: #pragma: no cover\n",
    "            raise RuntimeError(\"Give me two groups of the same dataset!\")\n",
    "        G1=list_G[0]\n",
    "    #Following method B in Notes - 27th October \n",
    "    \n",
    "    #first we \"correct\" the error distr\n",
    "    for Gi in list_G:\n",
    "        Gi.corr_distr,Gi.sys = corr_distr(Gi.err_distr,Gi.results)\n",
    "    comb_distr = np.hstack([Gi.corr_distr for Gi in list_G])\n",
    "    comb_res   = np.mean(comb_distr,axis=1) # always to consider if median or mean\n",
    "    comb_sys   = sqrt_sum_list([Gi.sys for Gi in list_G])\n",
    "    \n",
    "    #now we restore the error distr. as centered on the sys,\n",
    "    #while remembering the time result\n",
    "    comb_error       = Error()\n",
    "    comb_error.distr = [comb_distr[k] - comb_res[k] + comb_sys[k] for k in range(len(comb_sys))]\n",
    "    G_comb           = Group(data_distr = comb_distr, error = comb_error, labels = G1.labels)\n",
    "\n",
    "    G_comb.color = \"black\"\n",
    "    G_comb.name  = \"Combined \"+str([Gi.name.replace(\"Combined \",\"\")+\" and \" for Gi in list_G])\n",
    "    return G_comb\n",
    "\n",
    "\n",
    "def get_ref_index(series):\n",
    "    err = [G.tot_error for G in series]\n",
    "    ref_index = int(np.where(err==np.min(err))[0])\n",
    "    return ref_index\n",
    "\n",
    "def tau(dt_i,dt_j,sig_i,sig_j): \n",
    "    #simplified version bc considering method A\n",
    "    tau_val = abs(dt_i-dt_j)/sqrt_sum(sig_i,sig_j) #~ Z val\n",
    "    return tau_val\n",
    "\n",
    "def tau_G(G1,G2):\n",
    "    if G1.labels!=G2.labels: #pragma: no cover\n",
    "        raise RuntimeError(\"Give me two groups of the same dataset!\")\n",
    "    tau_G = []\n",
    "    for i in range(len(G1.labels)):\n",
    "        dt1  = G1.results[i]\n",
    "        dt2  = G2.results[i]\n",
    "        sig1 = G1.tot_error[i]\n",
    "        sig2 = G2.tot_error[i]\n",
    "        tau_G.append(tau(dt1,dt2,sig1,sig2))\n",
    "    return max(tau_G)\n",
    "\n",
    "#######################################################################\n",
    "# deprecated function. don't use\n",
    "def combine_series(series,sigmathresh=0.5,return_combined_list=False):\n",
    "    raise RuntimeWarning(\"Deprecated function, use methodB\")\n",
    "    series = copy.copy(series)\n",
    "    # find the reference group (most accurate overall)\n",
    "    ref_index = get_ref_index(series)\n",
    "    ref_G     = copy.copy(series[ref_index])\n",
    "    ignore_G  = [ref_G.name]\n",
    "    print(\"Initial best result: \",ref_G.name)\n",
    "    # check tension\n",
    "    tension_series =[] \n",
    "    for G in series:\n",
    "        if G.name not in ignore_G and tau_G(G,ref_G)>=sigmathresh:\n",
    "            tension_series.append(G)\n",
    "    \n",
    "    print(\"Combining results series...\")\n",
    "    while len(tension_series)>0:\n",
    "        tns_index = get_ref_index(tension_series)\n",
    "        tns_ref   = tension_series[tns_index]\n",
    "        ignore_G.append(tns_ref.name)\n",
    "        ref_G = combine_groups(ref_G,tns_ref)\n",
    "        tension_series =[]\n",
    "        for G in series:\n",
    "            if G.name not in ignore_G and tau_G(G,ref_G)>=sigmathresh:\n",
    "                tension_series.append(G)\n",
    "    print(\"Combined:\",ignore_G)\n",
    "    ref_G.name=r\"Combined result with $\\tau_{thresh}=$\"+str(sigmathresh)\n",
    "    ref_G.combined_names = ignore_G\n",
    "    if return_combined_list:\n",
    "        return ref_G,ignore_G\n",
    "    else:\n",
    "        return ref_G\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Try: method B (see Nov 2nd-3rd)\n",
    "def corr_distr(err_distr,dt_meas):\n",
    "    if len(np.transpose(err_distr))==len(dt_meas):\n",
    "        err_distr=np.transpose(err_distr)\n",
    "    elif not len(err_distr)==len(dt_meas):\n",
    "        raise RuntimeError(\"err_distr and dt_meas must have at least 1 dim in common, \\\n",
    "                           instead \",np.shape(err_distr),\" and \",np.shape(dt_meas))\n",
    "    corr_dist,sys = [],[]\n",
    "    for i in range(len(dt_meas)):\n",
    "        sys.append(np.mean(err_distr[i]))\n",
    "        corr_dist.append(err_distr[i]-sys[-1]+dt_meas[i])\n",
    "    return np.array(corr_dist),np.array(np.abs(sys))\n",
    "\n",
    "    \n",
    "def combine_groups_methodB(G1,G2):\n",
    "    if G1.labels!=G2.labels: #pragma: no cover\n",
    "        raise RuntimeError(\"Give me two groups of the same dataset!\")\n",
    "    \n",
    "    #Following method B in Notes - 27th October \n",
    "    \n",
    "    #first we \"correct\" the error distr\n",
    "    G1.corr_distr,G1.sys = corr_distr(G1.err_distr,G1.results)\n",
    "    G2.corr_distr,G2.sys = corr_distr(G2.err_distr,G2.results)\n",
    "    \n",
    "    #we now can combine them and obtain the dt resulting from the combine distr\n",
    "    #and compute the combined sys\n",
    "    comb_distr = np.hstack([G1.corr_distr,G2.corr_distr])\n",
    "    comb_res   = np.mean(comb_distr,axis=1) # always to consider if median or mean\n",
    "    comb_sys   = sqrt_sum(G1.sys,G2.sys)\n",
    "    \n",
    "    #now we restore the error distr. as centered on the sys,\n",
    "    #while remembering the time result\n",
    "    comb_error       = Error()\n",
    "    comb_error.distr = [comb_distr[k] - comb_res[k] + comb_sys[k] for k in range(len(comb_sys))]\n",
    "    G_comb           = Group(data_distr = comb_distr, error = comb_error, labels = G1.labels)\n",
    "    \n",
    "    G_comb.color = \"black\"\n",
    "    G_comb.name  = r\"Combined \"+G1.name.replace(\"Combined \",\"\")+\" and \"+G2.name.replace(\"Combined \",\"\")\n",
    "    return G_comb\n",
    "\n",
    "def get_sig_prime(group,i,prime=\"\"):\n",
    "    # see Notes 3rd Nov. '21\n",
    "    # -> corrected : see Notes 2th May '22\n",
    "    sig_up  = group.err_up[i]\n",
    "    sig_low = group.err_down[i]\n",
    "    sig_sys = group.sys_error[i]\n",
    "    sig_rnd = (sig_up+sig_low)/2.\n",
    "    q = np.sqrt(sig_rnd**2 + sig_sys**2) - sig_rnd\n",
    "    if prime==\"up\":\n",
    "        return  sig_up  + q \n",
    "    elif prime==\"low\":\n",
    "        return  sig_low + q\n",
    "    else:\n",
    "        raise ValueError(\"Either upper or lower error\")\n",
    "        \n",
    "def tau_G_methodB(G1,G2):\n",
    "    if G1.labels!=G2.labels: #pragma: no cover\n",
    "        raise RuntimeError(\"Give me two groups of the same dataset!\")\n",
    "    tau_G = []\n",
    "    for i in range(len(G1.labels)):\n",
    "        dt1  = G1.results[i]\n",
    "        dt2  = G2.results[i]\n",
    "        if dt1>dt2:\n",
    "            sig1 = get_sig_prime(G1,i,prime=\"low\")\n",
    "            sig2 = get_sig_prime(G2,i,prime=\"up\")\n",
    "        else:\n",
    "            sig1 = get_sig_prime(G1,i,prime=\"up\")\n",
    "            sig2 = get_sig_prime(G2,i,prime=\"low\")\n",
    "        tau = abs(dt1-dt2)/sqrt_sum(sig1,sig2)\n",
    "        tau_G.append(tau)\n",
    "    return max(tau_G)\n",
    "\n",
    "def combine_series_methodB(series,sigmathresh=0.5,return_combined_list=False):\n",
    "    warnings.warn(\"\\nWARNING: we are here using the method B to combine groups. \\\n",
    "    See notes of 27thOct.\\n\",)\n",
    "    series = copy.copy(series)\n",
    "    #Set all the group in the series to have the same bin\n",
    "    #comb_bins = get_bins(series,n_bins=150,return_bins=True) \n",
    "    #set all the series' group such that they are shifted and have their (shifted) density distribution\n",
    "    # find the reference group (most accurate overall)\n",
    "    ref_index = get_ref_index(series) # this, provided that each Group has its own tot_error,doens't change\n",
    "    ref_G     = copy.copy(series[ref_index])\n",
    "    ignore_G  = [ref_G.name]\n",
    "    print(\"Initial best result: \",ref_G.name)\n",
    "    # check tension\n",
    "    tension_series =[] \n",
    "    for G in series:\n",
    "        if G.name not in ignore_G and tau_G_methodB(G,ref_G)>=sigmathresh:\n",
    "            tension_series.append(G)\n",
    "    \n",
    "    print(\"Combining results series...\")\n",
    "    combined_indexes=[]\n",
    "    while len(tension_series)>0:\n",
    "        tns_index = get_ref_index(tension_series)\n",
    "        tns_ref   = tension_series[tns_index]\n",
    "        ignore_G.append(tns_ref.name)\n",
    "        combined_indexes.append(tns_index)\n",
    "        ref_G = combine_groups_methodB(ref_G,tns_ref)\n",
    "        tension_series =[]\n",
    "        for G in series:\n",
    "            if G.name not in ignore_G and tau_G_methodB(G,ref_G)>=sigmathresh:\n",
    "                tension_series.append(G)\n",
    "    print(\"Combined:\",ignore_G)\n",
    "    ref_G.name+=r\"\\nCombined result with $\\tau_{thresh}=$\"+str(sigmathresh)\n",
    "    ref_G.combined_names = ignore_G\n",
    "    if return_combined_list:\n",
    "        return ref_G,ignore_G,combined_indexes\n",
    "    else:\n",
    "        return ref_G\n",
    "    \n",
    "def combine_series_methodB(series,sigmathresh=0.5):#,return_combined_list=False):\n",
    "    warnings.warn(\"\\nWARNING: we are here using the method B to combine groups. \\\n",
    "    See notes of 27thOct.\\n\",)\n",
    "    series = copy.copy(series)\n",
    "    #Set all the group in the series to have the same bin\n",
    "    #comb_bins = get_bins(series,n_bins=150,return_bins=True) \n",
    "    #set all the series' group such that they are shifted and have their (shifted) density distribution\n",
    "    # find the reference group (most accurate overall)\n",
    "    ref_index = get_ref_index(series) # this, provided that each Group has its own tot_error,doens't change\n",
    "    ref_G     = copy.copy(series[ref_index])\n",
    "    ignore_G  = [ref_G.name]\n",
    "    print(\"Initial best result: \",ref_G.name)\n",
    "    # check tension\n",
    "    tension_series =[] \n",
    "    for G in series:\n",
    "        if G.name not in ignore_G and tau_G_methodB(G,ref_G)>=sigmathresh:\n",
    "            tension_series.append(G)\n",
    "    \n",
    "    print(\"Combining results series...\")\n",
    "    combined_indexes=[]\n",
    "    while len(tension_series)>0:\n",
    "        tns_index = get_ref_index(tension_series)\n",
    "        tns_ref   = tension_series[tns_index]\n",
    "        ignore_G.append(tns_ref.name)\n",
    "        combined_indexes.append(tns_index)\n",
    "        ref_G = combine_groups_methodB(ref_G,tns_ref)\n",
    "        tension_series =[]\n",
    "        for G in series:\n",
    "            if G.name not in ignore_G and tau_G_methodB(G,ref_G)>=sigmathresh:\n",
    "                tension_series.append(G)\n",
    "    print(\"Combined:\",ignore_G)\n",
    "    ref_G.name+=r\"\\nCombined result with $\\tau_{thresh}=$\"+str(sigmathresh)\n",
    "    ref_G.combined_names = ignore_G\n",
    "    return ref_G"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
