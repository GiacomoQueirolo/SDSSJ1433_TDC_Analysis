{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod from Notes 19th october: we consider a spline ml and see the difference with the only polynomial case \n",
    "#-> Expected: larger error distribution, smaller systematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script will find the generative noise model parameters that create mock lightcurves matching the data properties in term of gaussian and correlated noise\n",
    "You can also provide directly the correct parameters in the config file. In this case I will just generate the python files to proceed to the step 3b and 3c\n",
    "and skip the optimisation\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os,sys\n",
    "import glob,time\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pathlib as pth\n",
    "import argparse as ap\n",
    "from corner import quantile\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocess import Pool, cpu_count\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#import pycs3.sim.run\n",
    "import pycs3.gen.util\n",
    "#import pycs3.sim.draw\n",
    "import pycs3.gen.splml \n",
    "import pycs3.spl.topopt\n",
    "import pycs3.gen.lc_func\n",
    "import pycs3.sim.twk as twk\n",
    "import pycs3.pipe.optimiser\n",
    "import pycs3.pipe.pipe_utils as ut\n",
    "\n",
    "####################\n",
    "from tools import *\n",
    "from stnd_plot import delayplot,dmagplot\n",
    "from stnd_handling_data import * #Error,getresults,combine_series, combine_series_methodB\n",
    "from plot_distrib import plot_err\n",
    "from stnd_red_chi import get_chi_red\n",
    "from pycs3_mod.sim.run import multirun\n",
    "from pycs3_mod.sim.draw import multidraw\n",
    "from inspect_results import plt_err, plt_err_tot, plt_intr_err\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "########### Script 1 ############\n",
    "#################################\n",
    "\n",
    "def setup_directories(config):\n",
    "    if not os.path.exists(config.config_directory):\n",
    "        print(\"I will create the config directory for you ! \")\n",
    "        mkdir(config.config_directory)\n",
    "    if not os.path.exists(config.general_directory):\n",
    "        print(\"I will create the general directory for you ! \")\n",
    "        mkdir(config.general_directory)\n",
    "    if not os.path.exists(config.lens_directory):\n",
    "        print(\"I will create the lens directory for you ! \")\n",
    "        mkdir(config.lens_directory)\n",
    "    if not os.path.exists(config.analysis_directory):\n",
    "        print(\"I will create the analysis directory for you ! \")\n",
    "        mkdir(config.analysis_directory)   \n",
    "    if not os.path.exists(config.simu_directory):\n",
    "        print(\"I will create the simulation directory for you ! \")\n",
    "        mkdir(config.simu_directory)\n",
    "        \n",
    "    if not os.path.exists(config.figure_directory):\n",
    "        print(\"I will create the figure directory for you ! \")\n",
    "        mkdir(config.figure_directory)\n",
    "    if not os.path.exists(config.report_directory):\n",
    "        print(\"I will create the report directory for you ! \")\n",
    "        mkdir(config.report_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "########### Script 2 ############\n",
    "#################################\n",
    "\"\"\"\n",
    "This script fit spline and regression difference to the data. This original fit will be used to create \n",
    "the generative noise model.\n",
    "You can tune the spline parameters from the config file.\n",
    "\"\"\"\n",
    "\n",
    "def init_fit(config):\n",
    "\n",
    "    savefig_path=pth.Path(config.simu_directory)    \n",
    "    for knt_i, knt in enumerate(config.knotstep_marg): #knotstep of the intr.spline\n",
    "        saveknt_path = savefig_path/str(\"simulation_kn\"+str(knt))\n",
    "        mkdir(savefig_path)        \n",
    "        for mlt_i, mltype_i in enumerate(config.mltype): #ml type\n",
    "            for mlc_i,ml_config in enumerate(config.ml_config[mlt_i]):\n",
    "                mllist_name,mlfp = ml_config \n",
    "                kwargs_ml = {\"mltype\":mltype_i,\"mllist_name\":mllist_name}\n",
    "                \n",
    "                if mltype_i==\"polyml\":\n",
    "                    mlfp_str=\"_mlfp_\"+str(mlfp)\n",
    "                    kwargs_ml[\"mlfp\"] = mlfp\n",
    "                elif mltype_i==\"splml\":\n",
    "                    if config.forcen:\n",
    "                        mlfp_str=\"_nmlspl_\"+str(mlfp)\n",
    "                    else:\n",
    "                        mlfp_str=\"_knstml_\"+str(mlfp)\n",
    "                    kwargs_ml[\"forcen\"] = config.forcen\n",
    "                    kwargs_ml[\"nmlspl\"] = mlfp\n",
    "                saveml_path = saveknt_path/config.get_savemlpath(mltype_i,ml_config)# saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str) \n",
    "                #MOD_ROB\n",
    "                if not check_success_analysis(get_analdir(saveml_path)):\n",
    "                    print(\"Analysis from \"+get_analdir(saveml_path)+\" was not sufficiently precise. Ignored.\")\n",
    "                    continue\n",
    "                savefigml_path =saveml_path/\"init_splines_and_resid/\"\n",
    "\n",
    "                #mkdir\n",
    "                saveml_path = str(saveml_path)+\"/\"\n",
    "                mkdir(saveml_path)\n",
    "                savefigml_path = str(savefigml_path)+\"/\"\n",
    "                mkdir(savefigml_path)\n",
    "                \n",
    "                lcs = config.get_lcs()\n",
    "                \n",
    "                if config.magshift is None :\n",
    "                    magsft = [-np.median(lc.getmags()) for lc in lcs]\n",
    "                else :\n",
    "                    magsft = config.magshift\n",
    "                pycs3.gen.lc_func.applyshifts(lcs, config.timeshifts, magsft) #remove median and set the time shift to the initial guess\n",
    "                config.attachml(lcs, kwargs_ml)  # add microlensing\n",
    "                \n",
    "                spline = config.spl1(lcs, kn=knt)\n",
    "                \n",
    "                rls = pycs3.gen.stat.subtract(lcs, spline)\n",
    "                \n",
    "                chi_red = get_chi_red(spline,kwargs_ml,nl_lc=len(lcs))\n",
    "\n",
    "                pycs3.gen.lc_func.display(lcs, [spline], showlegend=True, showdelays=True,filename=savefigml_path + \"spline_fit.png\")\n",
    "                pycs3.gen.stat.plotresiduals([rls], filename=savefigml_path + \"residual_fit.png\")\n",
    "\n",
    "                # and write data, again\n",
    "                #if not os.path.isdir(config.lens_directory + config.combkw[i, j]):\n",
    "                #    os.mkdir(config.lens_directory + config.combkw[i, j])\n",
    "\n",
    "                pycs3.gen.util.writepickle((lcs, spline), saveml_path+'/initopt.pkl')\n",
    "                \n",
    "                with open(saveml_path+'chi_red.txt', 'w') as f:\n",
    "                    f.write('chi_red: '+str(np.round(chi_red,4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################################\n",
    "################################\n",
    "##### actually my analysis #####\n",
    "################################\n",
    "################################\n",
    "################################\n",
    "\n",
    "# > actually best to keep it separated\n",
    "\n",
    "# Standard_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "########### Script 3a ###########\n",
    "#################################\n",
    "\n",
    "from test_optimiser import MyDicOptimiser\n",
    "def run_DIC(lcs,spline, fit_vector, kn, mlparams, optim_directory, config, stream, tolerance=0.75):\n",
    "    pycs3.sim.draw.saveresiduals(lcs, spline)\n",
    "    print(\"I'll try to recover these parameters :\", fit_vector)\n",
    "    #dic_opt = pycs3.pipe.optimiser.DicOptimiser(lcs, fit_vector, spline, config.attachml, mlparams, knotstep=kn,\n",
    "    dic_opt = MyDicOptimiser(lcs, fit_vector, spline, config.attachml, mlparams, knotstep=kn,\n",
    "                                    savedirectory=optim_directory,\n",
    "                                    recompute_spline=True, max_core=config.max_core,\n",
    "                                    n_curve_stat=config.n_curve_stat,\n",
    "                                    shotnoise=config.shotnoise_type, tweakml_type=config.tweakml_type,\n",
    "                                    tweakml_name=config.tweakml_name, display=config.display, verbose=False,\n",
    "                                    correction_PS_residuals=True, max_iter=config.max_iter, tolerance=tolerance,\n",
    "                                    theta_init=None)\n",
    "\n",
    "    chain = dic_opt.optimise()\n",
    "    dic_opt.analyse_plot_results()\n",
    "    chi2, B_best = dic_opt.get_best_param()\n",
    "    A = dic_opt.A_correction\n",
    "    dic_opt.reset_report()\n",
    "    dic_opt.report()\n",
    "\n",
    "    if dic_opt.success:\n",
    "        print(\"I succeeded finding a parameter falling in the %2.2f sigma from the original lightcurve.\" % tolerance)\n",
    "\n",
    "    else:\n",
    "        print(\"I didn't find a parameter that falls in the %2.2f sigma from the original lightcurve.\" % tolerance)\n",
    "        print(\"I then choose the best one... but be carefull ! \")\n",
    "\n",
    "    for k in range(len(lcs)):\n",
    "        def tweakml_PS_NUMBER(lcs, spline):\n",
    "            return twk.tweakml_PS(lcs, spline, B_PARAM, f_min=1 / 300.0, psplot=False, verbose=False,\n",
    "                                  interpolation='linear', A_correction=A_PARAM)\n",
    "\n",
    "        ut.write_func_append(tweakml_PS_NUMBER, stream,\n",
    "                             B_PARAM=str(B_best[k][0]), NUMBER=str(k + 1), A_PARAM=str(A[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_param_intrinsic(config):\n",
    "    \n",
    "    twk_dir = config.lens_directory+\"figure/\"\n",
    "    mkdir(twk_dir)\n",
    "    tweakml_plot_dir = twk_dir+'tweakml_plots/'\n",
    "    mkdir(tweakml_plot_dir)    \n",
    "    optim_directory = tweakml_plot_dir + 'twk_optim_%s_%s/' % (config.optimiser, config.tweakml_name)\n",
    "    mkdir(optim_directory)\n",
    "\n",
    "    savefig_path=pth.Path(config.simu_directory)\n",
    "    for knt_i, knt in enumerate(config.knotstep_marg): #knotstep of the intr.spline\n",
    "        saveknt_path = savefig_path/str(\"simulation_kn\"+str(knt))\n",
    "        for mlt_i, mltype_i in enumerate(config.mltype): #ml type\n",
    "            for mlc_i,ml_config in enumerate(config.ml_config[mlt_i]):  \n",
    "                mllist_name,mlfp = ml_config \n",
    "                kwargs_ml = {\"mltype\":mltype_i,\"mllist_name\":mllist_name}\n",
    "                if mltype_i==\"polyml\":\n",
    "                    mlfp_str=\"_mlfp_\"+str(mlfp)\n",
    "                    kwargs_ml[\"mlfp\"] = mlfp\n",
    "                elif mltype_i==\"splml\":\n",
    "                    if config.forcen:\n",
    "                        mlfp_str=\"_nmlspl_\"+str(mlfp)\n",
    "                    else:\n",
    "                        mlfp_str=\"_knstml_\"+str(mlfp)\n",
    "                    kwargs_ml[\"forcen\"] = config.forcen\n",
    "                    kwargs_ml[\"nmlspl\"] = mlfp\n",
    "\n",
    "                    \n",
    "                combdir = saveknt_path/config.get_savemlpath(mltype_i,ml_config)# saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str)\n",
    "                combdir = str(combdir)\n",
    "                \n",
    "                #MOD_ROB\n",
    "                if not check_success_analysis(get_analdir(combdir)):\n",
    "                    print(\"Analysis from \"+get_analdir(combdir)+\" was not sufficiently precise. Ignored.\")\n",
    "                    continue\n",
    "                    \n",
    "                mkdir(combdir)\n",
    "                \n",
    "                if not os.path.isdir(combdir):\n",
    "                    #os.mkdir(comb)\n",
    "                    raise RuntimeError(\"This directory should already exist: \",combdir)\n",
    "                    \n",
    "                f = open(combdir + '/tweakml_' + config.tweakml_name + '.py', 'w+')\n",
    "            \n",
    "                f.write('import pycs3 \\n')\n",
    "                f.write('from pycs3.sim import twk as twk \\n')    \n",
    "            \n",
    "                lcs, spline = pycs3.gen.util.readpickle(combdir+'/initopt.pkl' )\n",
    "            \n",
    "                pycs3.gen.mrg.colourise(lcs)\n",
    "                pycs3.gen.lc_func.display(lcs,[spline],nicefont=True,showdelays=True,\n",
    "                        filename=combdir+\"/spline_fit.png\")\n",
    "                fit_vector = pycs3.pipe.optimiser.get_fit_vector(lcs, spline)  # we get the target parameter now\n",
    "\n",
    "                # We need spline microlensing for tweaking the curve, if it is not the case we change it here to a flat spline that can be tweaked.\n",
    "                # the resulting mock light curve will have no ML anyway, we will attach it the ML defined in your config file before optimisation.\n",
    "                polyml = False\n",
    "                for k, l in enumerate(lcs):\n",
    "                    if l.ml == None:\n",
    "                        print('I dont have ml, I have to introduce minimal extrinsic variation to generate the mocks. Otherwise I have nothing to modulate.')\n",
    "                        pycs3.gen.splml.addtolc(l, n=2)\n",
    "                    elif l.ml.mltype == 'poly':\n",
    "                        print('I have polyml and it can not be tweaked. I will replace it with a flat spline just for the mock light curve generation.')\n",
    "                        l.rmml()\n",
    "                        polyml = True\n",
    "                \"\"\"\n",
    "                # we replace the spline optimised with poly ml by one without ml \n",
    "                spline = pycs3.spl.topopt.opt_fine(lcs, nit=5, knotstep=knt,verbose=False, bokeps=knt / 3.0,\n",
    "                                                       stabext=100) \n",
    "                for l in lcs:\n",
    "                    pycs3.gen.splml.addtolc(l, n=2)\n",
    "                pycs3.gen.util.writepickle((lcs, spline),combdir + '/initopt_generative_polyml.pkl')\n",
    "                \"\"\"\n",
    "                if polyml:\n",
    "                    # we replace the spline optimised with poly ml by one without ml\n",
    "                    # redo: we only add splml to the lcs \n",
    "                    spline = pycs3.spl.topopt.opt_fine(lcs, nit=5, knotstep=knt,verbose=False, bokeps=knt / 3.0,stabext=100) \n",
    "                    for l in lcs:\n",
    "                        pycs3.gen.splml.addtolc(l, n=2)\n",
    "                    pycs3.gen.util.writepickle((lcs, spline),combdir + '/initopt_generative_polyml.pkl')\n",
    "\n",
    "                # Starting to write tweakml function depending on tweak_ml_type :\n",
    "                run_DIC(lcs, spline, fit_vector, knt, kwargs_ml, optim_directory, config, f)\n",
    "                list_string = 'tweakml_list = ['\n",
    "                for k in range(len(lcs)):\n",
    "                    list_string += 'tweakml_PS_' + str(k + 1) + ','\n",
    "                list_string += ']'\n",
    "                f.write('\\n')\n",
    "                f.write(list_string)\n",
    "                f.close()\n",
    "                \n",
    "                ###\n",
    "                ### These should only be relative to the reports which I don't consider\n",
    "                ### for now ignore them\n",
    "                ###\n",
    "                \"\"\"\n",
    "                # rename the file :\n",
    "                files = [file for file in os.listdir(optim_directory)\n",
    "                         if os.path.isfile(os.path.join(optim_directory, file)) and (string_ML not in file)]\n",
    "    \n",
    "                for file in files:\n",
    "                    prefix, extension = file.split('.')\n",
    "                    os.rename(os.path.join(optim_directory, file),\n",
    "                    os.path.join(optim_directory, prefix + \"_kn%i_ml%s_%s%i.\" % (kn,ml[0], string_ML, ml[1]) + extension))\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "########### Script 3b ###########\n",
    "#################################\n",
    "\n",
    "\"\"\"\n",
    "This scrip will create copy of the data and mock light curves, according to your generative noise model.\n",
    "I am using multithreading to do that.\n",
    "\"\"\"\n",
    "     \n",
    "def draw_mock_para(config, combdir):\n",
    "    current_dir = os.getcwd()\n",
    "    os.chdir(combdir)\n",
    "    lcs, spline = pycs3.gen.util.readpickle('initopt.pkl')\n",
    "\n",
    "    pycs3.sim.draw.saveresiduals(lcs, spline)\n",
    "    \"\"\"\n",
    "    # add splml so that mytweakml will be applied by multidraw\n",
    "    for l in lcs:\n",
    "        if l.ml is None:\n",
    "            pycs3.gen.splml.addtolc(l, n=2)\n",
    "        elif l.ml.mltype == 'poly':\n",
    "            polyml = True\n",
    "            l.rmml()\n",
    "            \n",
    "    lcs, spline = pycs3.gen.util.readpickle('initopt_generative_polyml.pkl')\n",
    "    pycs3.sim.draw.saveresiduals(lcs, spline)\n",
    "    \"\"\"\n",
    "    # add splml so that mytweakml will be applied by multidraw\n",
    "    polyml = False\n",
    "    for l in lcs:\n",
    "        if l.ml is None:\n",
    "            pycs3.gen.splml.addtolc(l, n=2)\n",
    "        elif l.ml.mltype == 'poly':\n",
    "            polyml = True\n",
    "    if polyml:   \n",
    "        lcs, spline = pycs3.gen.util.readpickle('initopt_generative_polyml.pkl')\n",
    "        pycs3.sim.draw.saveresiduals(lcs, spline)\n",
    "        \n",
    "    # import the module with the parameter of the noise :\n",
    "    #print('I will use the parameter from : %s' % ('tweakml_' + config.tweakml_name + '.py'))\n",
    "    exec(compile(open('tweakml_' + config.tweakml_name + '.py', \"rb\").read(),\n",
    "                 'tweakml_' + config.tweakml_name + '.py', 'exec'), globals())\n",
    "\n",
    "    multidraw(lcs, spline, onlycopy=False, n=config.nsim, npkl=config.nsimpkls,\n",
    "                             simset=config.simset_mock, tweakml=tweakml_list,\n",
    "                             shotnoise=config.shotnoise_type, trace=False,\n",
    "                             truetsr=config.truetsr,trueMsr=config.trueMsr,\n",
    "                             shotnoisefrac=1.0, scaletweakresi=False)\n",
    "    os.chdir(current_dir)\n",
    "\n",
    "\n",
    "def draw_mock_para_aux(arguments):\n",
    "    return draw_mock_para(*arguments)\n",
    "\n",
    "def my_draw_mocks(config):   \n",
    "    if config.max_core is None:\n",
    "        processes = cpu_count()\n",
    "    else:\n",
    "        processes = config.max_core\n",
    "\n",
    "    p = Pool(processes=processes)\n",
    "    print(\"Running on %i cores. \" % processes)\n",
    "    \n",
    "    job_args = []\n",
    "    \n",
    "    savefig_path=pth.Path(config.simu_directory)\n",
    "    for knt_i, knt in enumerate(config.knotstep_marg): #knotstep of the intr.spline\n",
    "        saveknt_path = savefig_path/str(\"simulation_kn\"+str(knt))\n",
    "        for mlt_i, mltype_i in enumerate(config.mltype): #ml type\n",
    "            for mlc_i,ml_config in enumerate(config.ml_config[mlt_i]):  \n",
    "                mllist_name,mlfp = ml_config \n",
    "                if mltype_i==\"polyml\":\n",
    "                    mlfp_str=\"_mlfp_\"+str(mlfp)\n",
    "                elif mltype_i==\"splml\":\n",
    "                    if config.forcen:\n",
    "                        mlfp_str=\"_nmlspl_\"+str(mlfp)\n",
    "                    else:\n",
    "                        mlfp_str=\"_knstml_\"+str(mlfp)\n",
    "                combdir = saveknt_path/config.get_savemlpath(mltype_i,ml_config)# saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str) saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str)\n",
    "                combdir = str(combdir)\n",
    "                #MOD_ROB\n",
    "                if not check_success_analysis(get_analdir(combdir)):\n",
    "                    print(\"Analysis from \"+get_analdir(combdir)+\" was not sufficiently precise. Ignored.\")\n",
    "                    continue\n",
    "                simset = config.simset_mock\n",
    "                file = glob.glob(os.path.join(combdir, \"sims_\" + simset + '/*.pkl'))\n",
    "                if len(file) != 0:\n",
    "                    for f in file:\n",
    "                        os.remove(f)\n",
    "                job_args.append((config,combdir))\n",
    "    if processes > 1:\n",
    "        p.map(draw_mock_para_aux, job_args)\n",
    "    else:\n",
    "        for args in job_args:\n",
    "            draw_mock_para(*args)\n",
    "    print(\"Done draw mocks\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "########### Script 3c ###########\n",
    "#################################\n",
    "\n",
    "\n",
    "# I try to readapt the script from pycs 3c_optimise_copy_mocks.py so that I can use it even if the analysis is mine\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Optimise the copy and mock data. WARNING : this may take loooooooong. You probably want to launch that on several cores.\n",
    "I'm not re-running on already optimized lcs ! It should be safe to launch this script many times, it will run on different batch of lightcurves.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def exec_worker_mocks_aux(args):\n",
    "    return exec_worker_mocks(*args)\n",
    "\n",
    "\n",
    "\"\"\"def exec_worker_mocks(i, simset_mock, lcs, simoptfct, kwargs_optim, optset, tsrand, destpath,mltype,config):\n",
    "    print(\"worker %i starting...\" % i)\n",
    "    time.sleep(i)\n",
    "    sucess_dic = multirun(simset_mock, lcs, simoptfct, kwargs_optim=kwargs_optim,\n",
    "                        optset=optset, tsrand=tsrand, keepopt=True, destpath=destpath,mltype=mltype,config=config)\n",
    "    \n",
    "    return sucess_dic\n",
    "\"\"\"\n",
    "def exec_worker_mocks(i, config, lcs,  kwargs_optim, optset, destpath):\n",
    "    #j, config.simset_mock, lcs, config.simoptfct, kwargs, opts, config.tsrand, combdir\n",
    "    print(\"worker %i starting...\" % i)\n",
    "    time.sleep(i)\n",
    "    \n",
    "    sucess_dic = multirun(config,lcs, kwargs_optim=kwargs_optim,\n",
    "                        optset=optset,  keepopt=True, destpath=destpath)\n",
    "    \n",
    "    return sucess_dic\n",
    "\n",
    "def write_report_optimisation(f, success_dic):\n",
    "    if success_dic == None:\n",
    "        f.write('This set was already optimised.\\n')\n",
    "    else:\n",
    "        for i, dic in enumerate(success_dic):\n",
    "            f.write('------------- \\n')\n",
    "            if dic == None:\n",
    "                continue\n",
    "            if dic['success']:\n",
    "                f.write('None of the optimisations have failed for pickle %i. \\n' % i)\n",
    "            else:\n",
    "                f.write('The optimisation of the following curves have failed in pickle %i : \\n' % i)\n",
    "                for id in dic['failed_id']:\n",
    "                    f.write(\"   Curve %i :\" % id + str(dic['error_list'][0]) + ' \\n')\n",
    "                f.write('\\n')\n",
    "\n",
    "def clean_previous_simopt(config, lcs,  kwargs, opts, combdir):\n",
    "    # delete all previous optimisation\n",
    "    destdir = os.path.join(combdir, \"sims_%s_opt_%s\" % (config.simset_mock, opts))\n",
    "    try:\n",
    "        listdir = os.listdir(destdir)\n",
    "    except FileNotFoundError:\n",
    "        return 0       \n",
    "    for fi in listdir:\n",
    "        os.remove(destdir+\"/\"+fi)\n",
    "        \n",
    "def optimise_sim(config):\n",
    "    main_path = os.getcwd()\n",
    "    base_lcs = config.get_lcs() \n",
    "    f = open(os.path.join(config.report_directory, 'report_optimisation_%s.txt' % (config.simoptfctkw)), 'w')\n",
    "\n",
    "    savefig_path=pth.Path(config.simu_directory)\n",
    "    for knt_i, knt in enumerate(config.knotstep_marg): #knotstep of the intr.spline\n",
    "        saveknt_path = savefig_path/str(\"simulation_kn\"+str(knt))\n",
    "        for mlt_i, mltype_i in enumerate(config.mltype): #ml type\n",
    "            for mlc_i,ml_config in enumerate(config.ml_config[mlt_i]):  \n",
    "                lcs = copy.deepcopy(base_lcs)\n",
    "                mllist_name,mlfp = ml_config \n",
    "                kwargs_ml = {\"mltype\":mltype_i,\"mllist_name\":mllist_name}\n",
    "                if mltype_i==\"polyml\":\n",
    "                    mlfp_str=\"_mlfp_\"+str(mlfp)\n",
    "                    kwargs_ml[\"mlfp\"] = mlfp\n",
    "                elif mltype_i==\"splml\":\n",
    "                    if config.forcen:\n",
    "                        mlfp_str=\"_nmlspl_\"+str(mlfp)\n",
    "                    else:\n",
    "                        mlfp_str=\"_knstml_\"+str(mlfp)\n",
    "                    kwargs_ml[\"forcen\"] = config.forcen\n",
    "                    kwargs_ml[\"nmlspl\"] = mlfp\n",
    "                    \n",
    "                combdir = saveknt_path/config.get_savemlpath(mltype_i,ml_config)# saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str)\n",
    "                combdir = str(combdir)\n",
    "                #MOD_ROB\n",
    "                if not check_success_analysis(get_analdir(combdir)):\n",
    "                    print(\"Analysis from \"+get_analdir(combdir)+\" was not sufficiently precise. Ignored.\")\n",
    "                    continue\n",
    "                    \n",
    "                if config.magshift is None :\n",
    "                    magsft = [-np.median(lc.getmags()) for lc in lcs]\n",
    "                else :\n",
    "                    magsft = config.magshift\n",
    "\n",
    "                timeshifts = config.timeshifts\n",
    "                pycs3.gen.lc_func.applyshifts(lcs, timeshifts,magsft)  # be careful, this remove ml as well.\n",
    "            \n",
    "                # We also give them a microlensing model (here, similar to Courbin 2011)\n",
    "                config.attachml(lcs, kwargs_ml)  # this is because they were saved as raw lcs, wihtout lcs.\n",
    "\n",
    "                if config.max_core == None:\n",
    "                    nworkers = cpu_count() -2\n",
    "                else:\n",
    "                    nworkers = config.max_core\n",
    "                for c, opts in enumerate(config.optset):\n",
    "                    kwargs = {'kn': knt, 'name': config.simoptfctkw}\n",
    "                    kwargs = {**kwargs,**kwargs_ml} #combine the 2 dict\n",
    "                    print(\"I will run the optimiser on the simulated lcs with the parameters :\", kwargs)\n",
    "                    \"\"\"\n",
    "                    p = Pool(nworkers)\n",
    "                    #optfunc= lambda x: config.simoptfct(x)\n",
    "                    #def optfunc(lcs,**kwargs):\n",
    "                    #    return config.simoptfct(lcs,**kwargs)\n",
    "                    #job_args = [(j, config.simset_mock, lcs, config.simoptfct, kwargs, opts, config.tsrand, combdir) for j in range(nworkers)]\n",
    "                    job_args = [(j, config, lcs,  kwargs, opts, combdir) for j in range(nworkers)]\n",
    "                    clean_previous_simopt(*job_args[0][1:])\n",
    "                    success_list_simu = p.map(exec_worker_mocks_aux, job_args)\n",
    "                    p.close()\n",
    "                    p.join()\n",
    "                    \"\"\"\n",
    "                    job_args = [(j, config, lcs,  kwargs, opts, combdir) for j in range(nworkers)]\n",
    "                    clean_previous_simopt(*job_args[0][1:])\n",
    "                    #TEST\n",
    "                    success_list_simu=[]\n",
    "                    no_parall = False\n",
    "                    if mltype_i==\"polyml\":\n",
    "                        if mlfp==0 or mlfp==1:\n",
    "                            no_parall= True\n",
    "                    #TEST!!\n",
    "                    no_parall = True\n",
    "                    ########\n",
    "                    if no_parall:       \n",
    "                        job_args = (0, config, lcs,  kwargs, opts, combdir)\n",
    "                        success_list_simu = exec_worker_mocks_aux(job_args)  \n",
    "                        success_list_simu = [success_list_simu] \n",
    "                    else:\n",
    "                        p = Pool(nworkers)\n",
    "                        success_list_simu = p.map(exec_worker_mocks_aux, job_args)\n",
    "                        p.close()\n",
    "                        p.join()\n",
    "                    f.write('SIMULATIONS, kn%i, %s%s, optimiseur %s : \\n' % (knt, str(ml_config[0]),str(ml_config[1]), kwargs['name']))\n",
    "                    write_report_optimisation(f, success_list_simu)\n",
    "                    f.write('################### \\n')\n",
    "    print(\"OPTIMISATION DONE : report written in %s\" % (os.path.join(config.report_directory, 'report_optimisation_%s.txt' % config.simoptfctkw)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "########### Script 4a ###########\n",
    "#################################\n",
    "# plotting the error distribution mostly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### From compare_sys.ipynb ########\n",
    "def get_res_Group_i(config,knt,mltype,ml_config):\n",
    "    \"\"\"\n",
    "    Get the result Group\n",
    "    \"\"\"\n",
    "    \n",
    "    savefig_path=pth.Path(config.analysis_directory)\n",
    "    saveknt_path = savefig_path/str(\"analysis_kn\"+str(knt))\n",
    "            \n",
    "    mllist_name,mlfp = ml_config \n",
    "    \"\"\"\n",
    "    kwargs_ml = {\"mltype\":mltype,\"mllist_name\":mllist_name}\n",
    "    if mltype==\"polyml\":\n",
    "        mlfp_str=\"_mlfp_\"+str(mlfp)\n",
    "        kwargs_ml[\"mlfp\"] = mlfp\n",
    "    else:\n",
    "        if config.forcen:\n",
    "            mlfp_str=\"_nmlspl_\"+str(mlfp)\n",
    "        else:\n",
    "            mlfp_str=\"_knstml_\"+str(mlfp)\n",
    "        kwargs_ml[\"forcen\"] = config.forcen\n",
    "        kwargs_ml[\"nmlspl\"] = mlfp\n",
    "    \"\"\"\n",
    "    data_path = saveknt_path/config.get_savemlpath(mltype,ml_config)# saveknt_path/str(\"ml\"+mltype_i[:-2]+mllist_name+mlfp_str)\n",
    "    data_path = str(data_path)\n",
    "    sim_path  = get_simdir(data_path)#data_path.replace(\"Analysis\",\"Simulation\").replace(\"analysis\",\"simulation\")\n",
    "    sim_path  = sim_path+\"/sims_\" + config.simset_mock+\"_opt_\"+config.optset[0]\n",
    "\n",
    "    #ERROR\n",
    "    error = Error(sim_path)\n",
    "    error_distr = error.get_distr()\n",
    "    error.create_error()\n",
    "    #RES\n",
    "    res_Group = getresults(data_path,error=error,labels=config.delay_labels)\n",
    "    return res_Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_models(config,sigmathresh):\n",
    "    wddir = config.combined_directory \n",
    "    marginalisation_plot_dir = wddir+'/figure/marginalisation_plots/'\n",
    "    mkdir(marginalisation_plot_dir)        \n",
    "\n",
    "    indiv_marg_dir = marginalisation_plot_dir + config.name_marg_spline + '/'\n",
    "    mkdir(indiv_marg_dir)        \n",
    "\n",
    "    marginalisation_dir = wddir+ config.name_marg_spline + '/'\n",
    "    mkdir(marginalisation_dir)        \n",
    "\n",
    "    \n",
    "    f = open(marginalisation_dir + 'report_%s_sigma%2.1f.txt' % (config.name_marg_spline, sigmathresh), 'w')\n",
    "\n",
    "    colors = config.colors\n",
    "    color_id = 0\n",
    "\n",
    "    group_list = []\n",
    "\n",
    "    opt = config.optset[0]\n",
    "        \n",
    "    # Redefine the keyword here because you don't necessary want to marginalise over everything\n",
    "    # mlknotsteps_marg now correspond to ml_config, which therefore contains all combinations of ml_lc and degrees\n",
    "\n",
    "    masked_A = config.maskA\n",
    "    \n",
    "    savefig_path=pth.Path(config.analysis_directory)\n",
    "    for knt_i, knt in enumerate(config.knotstep_marg): #knotstep of the intr.spline\n",
    "        saveknt_path = savefig_path/str(\"analysis_kn\"+str(knt))\n",
    "        for mlt_i, mltype_i in enumerate(config.mltype): #ml type\n",
    "            for mlc_i,ml_config in enumerate(config.ml_config[mlt_i]):  \n",
    "                mllist_name,mlfp = ml_config \n",
    "                #MOD_ROB\n",
    "                combdir = saveknt_path/config.get_savemlpath(mltype_i,ml_config)\n",
    "                if not check_success_analysis(get_analdir(combdir)):\n",
    "                    print(\"Analysis from \"+get_analdir(combdir)+\" was not sufficiently precise. Ignored.\")\n",
    "                    continue\n",
    "                    \n",
    "                group_i = get_res_Group_i(config,knt,mltype_i,ml_config)\n",
    "                group_i.color=colors[color_id]\n",
    "                name = config.combkw[knt_i][mlt_i][mlc_i].replace(\"_\",\" \")+\" \"+str(mltype_i)+\" \"+str(mllist_name)+\" \"+str(mlfp)\n",
    "                group_i.name = name\n",
    "                group_list.append(group_i)\n",
    "                color_id += 1\n",
    "                if color_id >= len(colors):\n",
    "                    color_id = 0  # reset the color form the beginning\n",
    "                f.write('Set %s, knotstep : %2.2f, deg : %s %s \\n' % (name, knt, mllist_name,mlfp))\n",
    "                f.write('Tweak ml name : %s \\n' % config.tweakml_name_marg_spline[0])\n",
    "                f.write('------------------------------------------------ \\n')\n",
    "    \n",
    "    #combine results\n",
    "    \n",
    "    #combined = combine_series(group_list, sigmathresh=sigmathresh)\n",
    "    combined,comb_list,combined_indexes = combine_series_methodB(group_list, sigmathresh=sigmathresh,return_combined_list=True)\n",
    "    \n",
    "    \n",
    "    print(\"Final combination for marginalisation \", config.name_marg_spline)\n",
    "\n",
    "    savefig = indiv_marg_dir + config.name_marg_spline + \"_sigma_%2.2f_myplot.pdf\" % sigmathresh\n",
    "    \n",
    "    #create plot\n",
    "    delayplot(group_list,savefig,colors=colors,refgroup=combined,selected_groups_indexes=combined_indexes)\n",
    "    \n",
    "    print(\"Saved group_list as \",str(marginalisation_dir + config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_groups.pkl'),\\\n",
    "        \"and combined result as \",str(marginalisation_dir + config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_combined.pkl') )\n",
    "    pkl.dump(group_list,\n",
    "             open(marginalisation_dir + config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_groups.pkl',\n",
    "                  'wb'))\n",
    "    pkl.dump(combined,\n",
    "             open(marginalisation_dir + config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_combined.pkl',\n",
    "                  'wb'))\n",
    "    \n",
    "    #####################\n",
    "    # combine mag shift #\n",
    "    #####################\n",
    "    #mag_marginalisation_plot_dir = wddir+'/figure_MAG/marginalisation_plots/'\n",
    "    #mkdir(mag_marginalisation_plot_dir)\n",
    "    \n",
    "    #mag_indiv_marg_dir = mag_marginalisation_plot_dir + config.name_marg_spline + '/'\n",
    "    #mkdir(mag_indiv_marg_dir)        \n",
    "    #mag_marginalisation_dir = wddir+ config.name_marg_spline + '/mag/'\n",
    "    #mkdir(mag_marginalisation_dir)   \n",
    "    \n",
    "    series_to_combine = []\n",
    "    for name_to_comb in comb_list :\n",
    "        \"\"\"\n",
    "        str_to_comb = name_to_comb.replace(\" \",\"_\").replace(\"spl1_\",\"\") \n",
    "        \n",
    "        knt = int(str_to_comb.split(\"_\")[0].replace(\"ks\",\"\"))\n",
    "        try:\n",
    "            mltype =  str_to_comb.split(\"_\")[1].replace(\"ml\",\"\")\n",
    "            if \"spl\" in mltype:\n",
    "                mlfp_ = \"nmlspl_\"\n",
    "            elif \"poly\" in mltype:\n",
    "                mlfp_ = \"mlfp_\"\n",
    "            mlfp  = mlfp_+ str(str_to_comb.split(\"_\")[-1])\n",
    "            ml_dir = \"/ml\"+mltype+\"_\"+mlfp\n",
    "        except IndexError:\n",
    "            # no ml\n",
    "            noml = True\n",
    "            ml_dir= \"/\"\n",
    "        mlfp  = mlfp_+ str(str_to_comb.split(\"_\")[-1])\n",
    "        \"\"\"\n",
    "        lst_str  = name_to_comb.split(\" \")[1:]\n",
    "        knt      = int(lst_str[0].replace(\"ks\",\"\"))\n",
    "        mltype   = lst_str[1]\n",
    "        mlconfig = lst_str[-2:]\n",
    "\n",
    "        ml_dir      = config.get_savemlpath(mltype,mlconfig)\n",
    "\n",
    "        anl_path    = pth.Path(config.analysis_directory)\n",
    "        anlknt_path = anl_path/str(\"analysis_kn\"+str(knt))\n",
    "        data_path   = str(anlknt_path)+\"/\"+ml_dir\n",
    "        sim_path    = get_simdir(data_path)#data_path.replace(\"Analysis\",\"Simulation\").replace(\"analysis\",\"simulation\")\n",
    "        sim_path    = sim_path+\"/sims_\" + config.simset_mock+\"_opt_\"+config.optset[0]\n",
    "\n",
    "        #ERROR\n",
    "        error = Error_mag(sim_path)\n",
    "        error.create_error()\n",
    "        #RES\n",
    "        res_Group = getresults_mag(data_path,error=error,labels=[\"AB\",\"AC\",\"BC\"],name=name_to_comb)\n",
    "        series_to_combine.append(res_Group)\n",
    "        \n",
    "    #mag_combined = series_to_combine[0]\n",
    "    #if len(series_to_combine)>1:\n",
    "    #    for G in series_to_combine[1:]:  \n",
    "    #        mag_combined = combine_groups(mag_combined,G)   \n",
    "    mag_combined = combine_group_list_methodB(series_to_combine)\n",
    "    #mag_combined = combine_series_methodB(series_to_combine,sigmathresh=float(\"inf\"))\n",
    "\n",
    "\n",
    "    print(\"Final combination for marginalisation \", config.name_marg_spline)\n",
    "\n",
    "    savefig = indiv_marg_dir +\"mag_\" +config.name_marg_spline + \"_sigma_%2.2f_myplot.pdf\" % sigmathresh\n",
    "    \n",
    "    #create plot\n",
    "    dmagplot(series_to_combine,savefig,colors=colors,refgroup=mag_combined)\n",
    "    \n",
    "    print(\"Saved group_list as mag_\",str(marginalisation_dir +  config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_groups.pkl'),\\\n",
    "        \"and combined result as mag_\",str(marginalisation_dir + config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_combined.pkl') )\n",
    "    pkl.dump(series_to_combine,\n",
    "             open(marginalisation_dir  +\"mag_\"+ config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_groups.pkl',\n",
    "                  'wb'))\n",
    "    pkl.dump(mag_combined,\n",
    "             open(marginalisation_dir  +\"mag_\"+ config.name_marg_spline + \"_sigma_%2.2f\" % sigmathresh + '_combined.pkl',\n",
    "                  'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_pipeline(config,verbose=False):    \n",
    "    #Creating missing directories\n",
    "    if verbose:\n",
    "        print(\"Setting up directories\\n\")\n",
    "    setup_directories(config)\n",
    "    #Assuming Standard_analysis alread run, if not to implement a way to run it at this point\n",
    "    # Simulation\n",
    "    if verbose:\n",
    "        print(\"Initial fit\\n\")\n",
    "    init_fit(config)\n",
    "    if verbose:\n",
    "        print(\"Setting intrinsic parameter\\n\")\n",
    "    set_param_intrinsic(config)\n",
    "    if verbose:\n",
    "        print(\"Drawing mocks\\n\")\n",
    "    my_draw_mocks(config)\n",
    "    # Optimise the simulation\n",
    "    if verbose:\n",
    "        print(\"Optimising the simulation\\n\")\n",
    "    optimise_sim(config)\n",
    "    # Plot resulting error distribution and original analysis distribution \n",
    "    if verbose:\n",
    "        print(\"Plotting the error distribution\\n\")\n",
    "    plot_err(config)\n",
    "    \n",
    "    print(\"Done standard error analysis\\n\")\n",
    "    \n",
    "    # Combine the results obtained from different models and plot them\n",
    "    if verbose:\n",
    "        print(\"Combining models\\n\")\n",
    "    combine_models(config,sigmathresh=config.sigmathresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = ap.ArgumentParser(prog=\"python {}\".format(os.path.basename(__file__)),\n",
    "                               description=\"Find the noise parameter to reproduce the data. Then prepare the copies of the light curves and draw some mock curves. \\\n",
    "                               Analyse them. Obtain the error distribution, and the corresponding systematic. Repeat the process with the time delay corrected for the systematic\",\n",
    "                               formatter_class=ap.RawTextHelpFormatter)\n",
    "    help_lensname = \"name of the lens to process\"\n",
    "    help_dataname = \"name of the data set to process (Euler, SMARTS, ... )\"\n",
    "    parser.add_argument(dest='lensname', type=str,\n",
    "                        metavar='lens_name', action='store',\n",
    "                        help=help_lensname)\n",
    "    parser.add_argument(dest='dataname', type=str,\n",
    "                        metavar='dataname', action='store',\n",
    "                        help=help_dataname)\n",
    "    parser.add_argument('-v','--verbose',help=\"Verbosity\",\n",
    "                        dest=\"verbose\", \n",
    "                        default=False,action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "    lensname = args.lensname\n",
    "    dataname = args.dataname\n",
    "    verbose  = args.verbose\n",
    "\n",
    "    present_program(sys.argv[0])\n",
    "\n",
    "\n",
    "    config = get_config(lensname=lensname,dataname=dataname,config_path=\"myconfig\")\n",
    "    dt_string = time.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(\"Running: \",sys.argv[0])\n",
    "    print(\"Machine: \",os.uname()[1]) \n",
    "    print(\"Config file:\", lensname+\"_\"+dataname)\n",
    "    print(\"Started the :\", dt_string)\n",
    "    print(\"#########################\")\n",
    "    standard_pipeline(config,verbose=verbose)\n",
    "\n",
    "    #### \n",
    "    inspect_err_dir = config.combined_directory +'/figure/marginalisation_plots/'\n",
    "    plt_err(config,savefig_dir=inspect_err_dir)\n",
    "    plt_err_tot(config,savefig_dir=inspect_err_dir)\n",
    "    plt_intr_err(config,savefig_dir=inspect_err_dir)\n",
    "    #### \n",
    "    ######\n",
    "    # FR mod\n",
    "    #from observed_FR import combine_models_mag\n",
    "    #combine_models_mag(config)\n",
    "    ######\n",
    "    print(\"\\n\",str(sys.argv[0]),\": Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
