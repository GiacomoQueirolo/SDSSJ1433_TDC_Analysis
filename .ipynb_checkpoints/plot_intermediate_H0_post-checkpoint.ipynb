{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plan to obtain intermediate H0 from single df of single filter model of lenstronomy and overplot the posterior\n",
    "\"\"\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import argparse\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import corner,pickle\n",
    "import json,copy,time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "from tools import *\n",
    "import pycs_get_res\n",
    "from get_res import *\n",
    "from Dt_from_Df import *\n",
    "from plotting_tools import base_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('figure',**{'figsize':(12,9)})\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_center(bins):\n",
    "    bins_centers = []\n",
    "    for i in range(len(bins)):\n",
    "        bins_centers_i = []\n",
    "        for j in range(len(bins[i])-1):\n",
    "            bins_centers_i.append((bins[i][j]+bins[i][j+1])/2.)\n",
    "        bins_centers.append(bins_centers_i)\n",
    "    bins_centers =np.array(bins_centers)\n",
    "    return bins_centers\n",
    "\n",
    "def get_analytic_density(mean,cov,bins,norm=1):\n",
    "    center_bins = get_bin_center(bins) \n",
    "    grid_of_points = np.transpose(np.meshgrid(*center_bins))\n",
    "    dens  = multivariate_normal.pdf(grid_of_points,mean,cov)*norm\n",
    "    return dens\n",
    "\n",
    "\n",
    "def get_normalisation(in_bins,Dt_kw,H0_range):\n",
    "    bins = np.array(copy.deepcopy(in_bins))\n",
    "    dH0 = H0_range[1]-H0_range[0] #is this necessary?\n",
    "    kwargs_df = {\"mean\":Df_XY(copy.deepcopy(Dt_kw[\"mean\"]),H0_range[0]),\n",
    "     \"cov\":cov_Df(copy.deepcopy(Dt_kw[\"cov\"]),H0_range[0])}\n",
    "    norm = get_analytic_density(bins=bins,**kwargs_df)\n",
    "    for i in range(1,len(H0_range)):\n",
    "        kwargs_df = {\"mean\":Df_XY(copy.deepcopy(Dt_kw[\"mean\"]),H0_range[i]),\n",
    "             \"cov\":cov_Df(copy.deepcopy(Dt_kw[\"cov\"]),H0_range[i])}\n",
    "        norm+= get_analytic_density(bins=bins,**kwargs_df)*dH0\n",
    "    print(\"normalisation done\")\n",
    "    return norm\n",
    "def get_bin_vol(in_bins):\n",
    "    bins =copy.deepcopy(in_bins)\n",
    "    dim = np.shape(bins)[0]\n",
    "    print(dim)\n",
    "    bin_vol = 1\n",
    "    for d in range(dim):\n",
    "        bin_lenght=bins[d][1]-bins[d][0] \n",
    "        for n in range(5):\n",
    "            rnd_index = np.random.randint(2,len(bins[d]))\n",
    "            test_lenght =bins[d][rnd_index]-bins[d][rnd_index-1]\n",
    "            if np.abs(bin_lenght-test_lenght)>1e-7:\n",
    "                raise RuntimeError(\"Not all bins have the same size\")\n",
    "        bin_vol *= bin_lenght\n",
    "    # we get a \"volume\" (vol in 3D, area in 2D, lenght in 1D) \n",
    "    # assuming that all bins are the same\n",
    "    return bin_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PH0(Dens_f,\n",
    "            nd_bins,\n",
    "            Dt_kw,\n",
    "            H0=np.arange(50,100,.1)):    \n",
    "    PH0 = []\n",
    "    for h0 in H0:\n",
    "        kwargs_df = {\"mean\":Df_XY(copy.deepcopy(kwargs_dt[\"mean\"]),h0),\n",
    "             \"cov\":cov_Df(copy.deepcopy(kwargs_dt[\"cov\"]),h0)}\n",
    "        Dens_f_trsf = get_analytic_density(bins=copy.deepcopy(nd_bins),**kwargs_df)\n",
    "        Dens_tot = copy.deepcopy(Dens_f)*Dens_f_trsf\n",
    "        # the integration in this case is nothing else then the sum over every bin, ie:\n",
    "        P_h0 = np.sum(Dens_tot)\n",
    "        if np.isnan(P_h0):\n",
    "            P_h0 = 0.\n",
    "        PH0.append(P_h0)\n",
    "    if np.sum(PH0)!=0:\n",
    "        PH0 = PH0/np.sum(PH0)\n",
    "    else:\n",
    "        print(\"WARNING: sum of PH0 == 0\")\n",
    "    return np.array(PH0),H0\n",
    "\n",
    "def quantiles_uncertainties(prob,sampling_prob,q=[0.16,.5,0.84],return_quantiles=False):\n",
    "    qnt    = []\n",
    "    integr = 0\n",
    "    for i in range(len(prob)):\n",
    "        integr+=prob[i]\n",
    "        for qi in q:\n",
    "            if integr-prob[i]<qi and integr>=qi:\n",
    "                qnt.append(sampling_prob[i])\n",
    "    if return_quantiles:\n",
    "        return qnt\n",
    "    else:\n",
    "        res     = qnt[1]\n",
    "        err_min = qnt[1]-qnt[0]\n",
    "        err_max = qnt[2]-qnt[1]\n",
    "        return (res,err_min,err_max)\n",
    "\n",
    "    \n",
    "# Litt. Data\n",
    "h0planck = 67.4 # km/s/Mpc\n",
    "h0planck_err = 0.5\n",
    "h0licow  = 73.3 # km/s/Mpc\n",
    "h0licow_err = [1.8,1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data collected\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ################################\n",
    "    present_program(sys.argv[0])\n",
    "    ################################\n",
    "    parser = argparse.ArgumentParser(description=\"Temporary plot of the posterior of H0 from the given lens models\")\n",
    "    parser.add_argument(\"-nb\",\"--number_bins\",type=int, dest=\"nbins\", default=100,\n",
    "                    help=\"Number of bins per dimension for the histog. sampling of the Df (be careful with it! too many bins can be catastrophic)\")\n",
    "    parser.add_argument('-ln','--lensname',help=\"Lensname for time delay dataset to consider\",\n",
    "                        dest=\"lensname\", \n",
    "                        default=\"J1433\",action=\"store\")\n",
    "    parser.add_argument('-dn','--dataname',action='store',default=\"forcen\",\n",
    "                        help=\"Dataname for time delay dataset to consider\")\n",
    "    parser.add_argument('SETTING_FILES',nargs=\"+\",default=[],help=\"setting file(s) to consider\")\n",
    "    args  = parser.parse_args()\n",
    "    # bins for the fermat pot\n",
    "    bins  = args.nbins \n",
    "    setting_names =  args.SETTING_FILES\n",
    "    lensname = args.lensname\n",
    "    dataname = args.dataname\n",
    "    \n",
    "    #Dt:\n",
    "    print(\"Time delay result obtained from: \"+lensname+\"_\"+dataname)\n",
    "    pycs_path = \"./my_pycs_scripts/\"\n",
    "    dt_comb_res = pycs_get_res.get_combined_res(lensname+\"_\"+dataname,main_dir_path=pycs_path)\n",
    "    cov_sys =  (np.array(dt_comb_res.error.sys)**2)*np.identity(len(dt_comb_res.error.sys))\n",
    "    cov_rnd = np.cov(dt_comb_res.err_distr)\n",
    "    cov_dt  = cov_sys + cov_rnd\n",
    "    kwargs_dt = {\"mean\":dt_comb_res.results,\"cov\":cov_dt}\n",
    "    \n",
    "    backup_res_lnstr = \"./backup_results/\"\n",
    "    savefig_path     = backup_res_lnstr+\"/Post_H0/\"\n",
    "    mkdir(savefig_path)\n",
    "    \n",
    "    H0s  = []\n",
    "    PH0s = []\n",
    "    f,ax = plt.subplots(1,1,figsize=(12,12)) \n",
    "    for i,sets in enumerate(setting_names):\n",
    "        print(\"setting:\",sets)\n",
    "        mcmc_fermat = get_mcmc_fermat(sets)\n",
    "        mcmc_Df     = np.transpose(mcmc_fermat)[1:]-np.transpose(mcmc_fermat)[0]\n",
    "        mcmc_c      = np.array(copy.deepcopy(mcmc_Df))\n",
    "        mcmc_BC     = mcmc_c[1] - mcmc_c[0]  # BC = C - B = (C-A)-(B-A) = AC - AB\n",
    "        mcmc_c[2]   = mcmc_BC\n",
    "        mcmc_Df     = mcmc_c \n",
    "        print(\"WARNING: Given the low S/N of image D, I will discard here and instead consider Delta BC\")    \n",
    "        Post_Df,Post_Df_bins = np.histogramdd(mcmc_Df.T,bins=bins,density=True) \n",
    "        \n",
    "        PH0,H0 = get_PH0(Post_Df,Post_Df_bins,Dt_kw=kwargs_dt)\n",
    "        PH0s.append(PH0)\n",
    "        H0s.append(H0)\n",
    "        ax.scatter(H0,PH0,c=base_colors[i],label=strip_setting_name(sets),marker=\".\")\n",
    "        h0_res,err_min,err_max= quantiles_uncertainties(PH0,H0,return_quantiles=False)\n",
    "        yh0 = max(PH0)/2\n",
    "        str_res = str(np.round(h0_res,2))+\"$_{-\"+str(np.round(err_min,2))+\"}^{+\"+str(np.round(err_max,2))+\"}$\"\n",
    "        ax.errorbar(h0_res,yh0,yerr=None,xerr=[[err_min],[err_max]],fmt=base_colors[i],capsize=4)\n",
    "        ax.scatter(h0_res,yh0,c=base_colors[i],marker=\".\")\n",
    "        ax.text(h0_res-.5*len(str((np.round(h0_res,2)))),yh0*1.05,str_res,c=base_colors[i])\n",
    "\n",
    "\n",
    "    y_max = max([max(ph0) for ph0 in PH0s])\n",
    "    ax.axvline(h0planck,label=\"Planck\",c=\"r\",ls=\"--\")\n",
    "    ax.axvline(h0licow,label=\"H0LiCOW\",c=\"g\",ls=\"--\")\n",
    "    ax.fill_between(np.linspace(h0planck-h0planck_err ,h0planck+h0planck_err ) , -10, 10, color='red', alpha=0.2)\n",
    "    ax.fill_between(np.linspace(h0licow-h0licow_err[0] ,h0licow+h0licow_err[1] ) , -10, 10, color='green', alpha=0.2)\n",
    "    plt.ylim(0,y_max*1.1)\n",
    "    plt.xlabel(\"$H_0$[km/s/Mpc]\")\n",
    "    plt.ylabel(\"P($H_0$)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Compare $H_0$ posterior from individual filter's lens models\")\n",
    "    f.savefig(savefig_path+\"/compare_H0.png\")\n",
    "    print(\"Created \"+savefig_path+\"/compare_H0.png\")\n",
    "    \n",
    "    res_H0 = [H0s,PH0s]\n",
    "    with open(savefig_path+\"/H0s.pkl\",\"wb\") as f:\n",
    "        pickle.dump(res_H0,f)\n",
    "    success(sys.argv[0])    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
