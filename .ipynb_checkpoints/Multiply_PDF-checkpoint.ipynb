{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from statistical_tools import get_bins_volume\n",
    "# General function to multiply PDF  (can be applied to priors as well - and will be)\n",
    "\"\"\"def Multiply_PDF(samples,nbins=None,KDE=False,Priors=None,savedir=\".\"):\n",
    "    # samples.shape= (n_datasets,n_mcmc_points,n_dims)\n",
    "    # same for Priors\n",
    "    \n",
    "    if KDE is False and nbins is None:\n",
    "        raise RuntimeError(\"Nbins are required for the histogram sampling\")\n",
    "\n",
    "    if KDE:\n",
    "        Combined_PDF,Positions = Multiply_PDF_KDE(samples,Priors,savedir)\n",
    "        return Combined_PDF,Positions\n",
    "    else:\n",
    "        Combined_PDF, Combined_bins = Multiply_PDF_HIST(samples,nbins,Priors,savedir)\n",
    "        return Combined_PDF, Combined_bins \"\"\"\n",
    "    \n",
    "def get_minmax(samples,dim=None):\n",
    "    # We get the min and maximum for each dimension relatively to all the datasets togheter\n",
    "    if dim is not None:\n",
    "        return np.min([min(par_i) for par_i in np.array(samples,dtype=object)[:,dim]]),\\\n",
    "            np.max([max(par_i) for par_i in np.array(samples,dtype=object)[:,dim]])\n",
    "    else:\n",
    "        dim = len(samples[0])\n",
    "        min_i,max_i = [],[]\n",
    "        for d in range(dim):\n",
    "            min_i.append(np.min([min(par_i) for par_i in np.array(samples,dtype=object)[:,d]]))\n",
    "            max_i.append(np.max([max(par_i) for par_i in np.array(samples,dtype=object)[:,d]]))\n",
    "        return min_i,max_i\n",
    "    \n",
    "def Multiply_PDF_HIST(samples,nbins,Prior=None,NtotPrior=None,savedir=\".\"):\n",
    "    # Using histograms to obtain the 3D binned density for each datasets\n",
    "    PDFs,PDFs_bins = [],[]\n",
    "    N = len(samples)\n",
    "    param_dim = len(samples[0]) # the parametric dimension must be the same for all datasets \n",
    "    #First find the same bins for each dataset in all parametric dimensions\n",
    "    #DfABmin,DfABmax = get_minmax(samples,0)\n",
    "    #DfACmin,DfACmax = get_minmax(samples,1)\n",
    "    #DfBCmin,DfBCmax = get_minmax(samples,2)\n",
    "    mins,maxs  = get_minmax(samples)#[DfABmax,DfACmax,DfBCmax],[DfABmin,DfACmin,DfBCmin]\n",
    "    d_bins = []\n",
    "    for par_dim_i in range(param_dim): # for each parametric dim\n",
    "        # Find for each dataset the corresponding max and min\n",
    "        max_dimi = maxs[par_dim_i]\n",
    "        min_dimi = mins[par_dim_i]\n",
    "        diff_dimi = max_dimi-min_dimi\n",
    "        len_bin_dimi = diff_dimi/nbins\n",
    "        d_bins_dimi = [min_dimi]\n",
    "        for nbin_i in range(nbins):\n",
    "            d_bins_dimi.append(d_bins_dimi[-1]+len_bin_dimi)\n",
    "        d_bins.append(d_bins_dimi)\n",
    "    \n",
    "    # Then we make the 3D histogram    \n",
    "    PDFs,Combined_bins = hists_given_bins(samples,d_bins)\n",
    "    \n",
    "    if Prior is not None: # and Prior_LR is not None\n",
    "        #Prior,Positions_KDE_Prior = KDE_prior_corr(Prior_HR=Prior_HR,Prior_LR=Prior_LR,d_bins=d_bins)\n",
    "        Prior,Positions_KDE_Prior = KDE_prior_corr(Prior=Prior,NtotPrior=NtotPrior,d_bins=d_bins)\n",
    "        #Priors,Prior_bins = hists_given_bins(Priors,d_bins)\n",
    "        #if np.all(Combined_bins!=Prior_bins):\n",
    "        #    raise RuntimeError(\"Something went wrong with the binning\")\n",
    "    \n",
    "    Combined_PDF = PDFs[0]\n",
    "    for i in range(1,N):\n",
    "        Combined_PDF *= PDFs[i]\n",
    "        \n",
    "    # Check that the Combined PDF is not 0\n",
    "    check_combined(Combined_PDF,PDFs,PDFs_bins,HIST=\"True\")\n",
    "    \n",
    "    if Prior is not None:\n",
    "        \"\"\"Combined_Prior = Prior[0]\n",
    "        for i in range(1,N):\n",
    "            Combined_Prior *= Priors[i]\n",
    "        #Check that the Combined Prior is not 0\n",
    "        check_combined(Combined_Prior,KDE=True)\n",
    "        Combined_Prior /= np.sum(Combined_Prior*get_bins_volume(d_bins)) # normalised \n",
    "        \"\"\"\n",
    "        check_combined(Prior,KDE=True)\n",
    "        Norm_Prior = Prior/np.sum(Prior*get_bins_volume(d_bins))\n",
    "        from plotting_tools import plot_probability3D\n",
    "        plot = plot_probability3D(Norm_Prior,Combined_bins,labels=[\"AB\",\"AC\",\"AD\"],udm=\"\\\"\",alpha=0.3)\n",
    "        plot.savefig(str(savedir)+\"/Normalised_prior.png\")\n",
    "        for i in range(N-1):\n",
    "            Combined_PDF/=Norm_Prior                \n",
    "    return Combined_PDF, Combined_bins\n",
    "\n",
    "def check_combined(Combined_PDF,PDFs=None,PDFs_bins=None,HIST=False,KDE=False):\n",
    "    #Check superposition\n",
    "    if HIST:\n",
    "        if np.sum(Combined_PDF)==0.0:\n",
    "            for i in range(len(PDFs)):\n",
    "                print(i,\" Max :\",PDFs_bins[i][np.where(PDFs[i]==np.max(PDFs[i]))[0]])\n",
    "            raise RuntimeError(\"No superposition between posteriors. \\\n",
    "            Try adjusting the bin nummer or correcting the modelling procedure for one or more dataset\")\n",
    "    elif KDE:\n",
    "        if np.sum(Combined_PDF)==0.0:\n",
    "            raise RuntimeError(\"No superposition between posteriors. No idea yet how to solve it\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Give either KDE or HIST\")\n",
    "\n",
    "def hists_given_bins(samples,bins):\n",
    "    PDFs = []\n",
    "    PDFs_bins = []\n",
    "    for i in range(len(samples)):\n",
    "        smpl = np.array(samples[i]).tolist()\n",
    "        density,bins = np.histogramdd(smpl,bins=bins,density=True) \n",
    "        # density is norm given the area/volume of the bin\n",
    "        PDFs.append(density)\n",
    "        PDFs_bins.append(bins)\n",
    "        \n",
    "    #Sanity check\n",
    "    same_binning = True\n",
    "    for i in range(1,len(PDFs_bins)):\n",
    "        if np.all(PDFs_bins[i]!=PDFs_bins[0]):\n",
    "            same_binning = False\n",
    "            raise ValueError(\"We have a problem, we should have the same binning for each filter\")\n",
    "    if same_binning:\n",
    "        PDF_bins = PDFs_bins[0]\n",
    "        \n",
    "    return PDFs,PDF_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Multiply_PDF_KDE(samples,npoints,ratio=2,Priors=None,savedir=\".\" ):\n",
    "    \"\"\"\n",
    "    Main idea for the moment:\n",
    "        - get KDEs bandwiths\n",
    "        - train KDEs at set of points from MCMC (maybe subsample of it)\n",
    "        - set a set of points (~bin position) common for all KDEs\n",
    "        - multiply KDEs at these points positions\n",
    "        - we now have 1 KDE and a set of point where it has been evalueated\n",
    "        - normalised point wise\n",
    "    \"\"\"\n",
    "    #from sklearn.neighbors import KernelDensity\n",
    "    #from sklearn.model_selection import GridSearchCV\n",
    "    import scipy.stats as st\n",
    "\n",
    "    maxs,mins = get_minmax(samples)\n",
    "    N         = len(samples)\n",
    "    \n",
    "\n",
    "    # select ony 1/n points of the sample -> select last n points from the center of the sample\n",
    "    sparse_sample = []\n",
    "    for smpl_fi in samples:\n",
    "        points_smpl   = int(len(smpl_fi[0])/ratio)\n",
    "        sparse_sample.append(np.array(smpl_fi).T[-points_smpl:].T)\n",
    "\n",
    "        \n",
    "    npoints   = complex(0,npoints)\n",
    "    xx, yy,zz = np.mgrid[mins[0]:maxs[0]:npoints, mins[1]:maxs[1]:npoints, mins[2]:maxs[2]:npoints]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel(),zz.ravel()])\n",
    "\n",
    "    values    = [np.vstack(smpl) for smpl in sparse_sample]\n",
    "    \n",
    "    #kernels   = [st.gaussian_kde(np.transpose(vl)) for vl in values]\n",
    "    #pool      = Pool(processes=100)  \n",
    "    #kernels   = [pool.map(st.gaussian_kde,np.transpose(vl)) for vl in values]\n",
    "    #KDEs      = [np.reshape(krnl(np.transpose(positions)).T, xx.shape) for krnl in kernels]\n",
    "\n",
    "    with Pool(processes=100) as pool:\n",
    "        kernels   = [pool.starmap(st.gaussian_kde,((np.transpose(vl),),))[0] for vl in values]\n",
    "    \n",
    "    #kernels   = [st.gaussian_kde(np.transpose(vl)) for vl in values]\n",
    "    #KDEs      = [np.reshape(krnl(np.transpose(positions)).T, xx.shape) for krnll in kernels]\n",
    "    KDEs      = [np.reshape(krnl(positions).T, xx.shape) for krnl in kernels]\n",
    "\n",
    "    with open(save_dir/str(\"PDF_KDEs.pkl\"),\"wb\") as f:\n",
    "        pickle.dump(KDEs,f)\n",
    "    # we then have to sample the space\n",
    "\n",
    "    \n",
    "    Combined_PDF = KDEs[0]\n",
    "    for i in range(1,N):\n",
    "        Combined_PDF *= KDEs[i]\n",
    "    check_combined_PDF(Combined_PDF,KDE=True)\n",
    "    # normalise point-wise: Sum over all points =1\n",
    "    Combined_PDF /= np.sum(Combined_PDF)\n",
    "\n",
    "    # Prior computed here in the same position as the combined post -> only once\n",
    "\n",
    "    if Prior is not None:\n",
    "        # TEST: only once\n",
    "        Prior,Positions_KDE_Prior = KDE_prior([Prior],positions,shape=xx.shape)\n",
    "\n",
    "        Combined_Prior = Prior\n",
    "        \n",
    "        # Check that the Combined Prior is not 0\n",
    "        check_combined(Combined_Prior,HIST=\"False\")\n",
    "        #Combined_Prior /= np.sum(Combined_Prior*get_bins_volume(d_bins)) # normalised \n",
    "        Combined_Prior /= np.sum(Combined_Prior) # normalised \n",
    "        from plotting_tools import plot_probability3D\n",
    "        plot = plot_probability3D_KDE(Combined_Prior,Positions_KDE_Prior,labels=[\"AB\",\"AC\",\"AD\"],udm=\"\\\"\",alpha=0.3)\n",
    "        plot.savefig(str(savedir)+\"/Combined_prior.pdf\")\n",
    "        for i in range(N-1):\n",
    "            Combined_PDF/=Combined_Prior                \n",
    "    return Combined_PDF, positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDE_prior_corr(Prior, NtotPrior,d_bins,shape=None):\n",
    "    # Priors shape must be (point_i, dimensions), eg: (1000,3)\n",
    "    # Prior corrected for the Lower resolution\n",
    "    # return Priors evaluated with KDE at center of the bins\n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # find the best bandwidth for each filter\n",
    "    prior_bndws = 10 ** np.linspace(-1, 1, 100)\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'),{'bandwidth': prior_bndws})\n",
    "    # initial shape of samples: filter,dimension,step\n",
    "\n",
    "    bandwidth = grid.fit(Prior)\n",
    "    #bandwidth_LR = grid.fit(Prior_LR)\n",
    "    # input of grid.fit must have shape: ( n*steps, n*dimensions)\n",
    "\n",
    "    # define the KDE\n",
    "    kde = KernelDensity(**bandwidth.best_params_, kernel='gaussian') \n",
    "    #kde_LR = KernelDensity(**bandwidth_LR.best_params_, kernel='gaussian') \n",
    "    # Fit the KDE to the samples\n",
    "    KDE = kde.fit(Prior)\n",
    "    #KDE_LR = kde_LR.fit(Prior_LR)\n",
    "\n",
    "    # we then have to sample the space\n",
    "    if shape is None:\n",
    "        positions = KDE_position_from_bin(d_bins) #position.shape = ((n_bins-1)**Dim,Dim) \n",
    "        shape     = [len(b)-1 for b in d_bins]\n",
    "    else:\n",
    "        positions = d_bins\n",
    "    # NOTE 14th Nov '22:\n",
    "    # the prior is computed by summing the high res prior to the prior obtained\n",
    "    # from the low resolution \n",
    "    # They must have the same normalisation. First normalised \"pointwise\" both of them\n",
    "    # then the high res have to be adapted to the approximately correct normalisation of the\n",
    "    # low res prior. Then it have to be shifted st its average is 0\n",
    "    # and finally it can be shifted to the real average given by the low res one\n",
    "    Prior_val = KDE.score_samples(positions).reshape(*shape)\n",
    "    #Prior_val_LR = KDE_LR.score_samples(positions).reshape(*shape)\n",
    "    #shifted_PHR  = Prior_val - np.mean(Prior_val)\n",
    "    #Prior        = shifted_PHR  + Prior_val_LR\n",
    "    Prior = Prior_val* len(Prior)/NtotPrior\n",
    "    return Prior, positions\n",
    "\n",
    "def KDE_prior(Priors,d_bins,shape=None):\n",
    "    # Priors shape must be (filter_i, point_i, dimensions), eg: (1,1000,3)\n",
    "    # (same as standard smpl)\n",
    "    # return Priors evaluated with KDE at center of the bins\n",
    "    \n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # find the best bandwidth for each filter\n",
    "    prior_bndws = 10 ** np.linspace(-1, 1, 100)\n",
    "    grid = GridSearchCV(KernelDensity(kernel='gaussian'),{'bandwidth': prior_bndws})\n",
    "    # initial shape of samples: filter,dimension,step\n",
    "\n",
    "    #bandwidths = [ grid.fit(np.transpose(samples[filt_i])) for filt_i in range(len(filters)) ]   \n",
    "    bandwidths = [grid.fit(Prior_i) for Prior_i in Priors]   \n",
    "    # input of grid.fit must have shape: ( n*steps, n*dimensions)\n",
    "\n",
    "    # define the KDE\n",
    "    kdes = [KernelDensity(**bndw.best_params_, kernel='gaussian') for bndw in bandwidths]\n",
    "    # Fit the KDEs to the samples\n",
    "    KDEs = [kde.fit(Priors[i]) for i,kde in enumerate(kdes)]\n",
    "\n",
    "    # we then have to sample the space\n",
    "    if shape is None:\n",
    "        positions = KDE_position_from_bin(d_bins) #position.shape = ((n_bins-1)**Dim,Dim) \n",
    "        shape     = [len(b)-1 for b in d_bins]\n",
    "    else:\n",
    "        positions = d_bins\n",
    "        \n",
    "    Priors = [kde_i.score_samples(positions).reshape(*shape) for kde_i in KDEs]\n",
    "    \n",
    "    # NOTE: by construction the KDE is not normalised\n",
    "    # we could \"normalise\" it pointwise, but it is actually not necessary, \n",
    "    # as it is only shifted by a factor, and the Combined_PDF has to be normalised\n",
    "    # anyway after the multiplication\n",
    "    # but this is blocking the test so\n",
    "    #Priors = [Prior_i/np.sum(Prior_i*get_bin_volume(d_bins)) for Prior_i in Priors] # \"normalised\" \n",
    "    return Priors, positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDE_position_from_bin(d_bins):\n",
    "    # obtain center of 3D bins and return as\n",
    "    # positions for KDE -> shape: ((nbins-1)**Dim,Dim)\n",
    "    if len(d_bins)!=3:\n",
    "        raise ValueError(\"Implemented explicitely for 3 dimensions\")\n",
    "\n",
    "    # get the center of the bins instead of the edges\n",
    "    centers = []\n",
    "    for bi in d_bins:\n",
    "        cnt_di = [] # for each dim_i indep\n",
    "        for i in range(len(bi)-1):\n",
    "            cnt_di.append(.5*(bi[i]+bi[i+1]))\n",
    "        centers.append(cnt_di)\n",
    "    # From here on considering 3Dims\n",
    "    #\n",
    "    # Creating a grid of points from the matrix of centers\n",
    "    Dim1, Dim2, Dim3 = np.meshgrid(*centers)\n",
    "    # reorganising the shape of it\n",
    "    positions = np.vstack([Dim1.ravel(), Dim2.ravel(), Dim3.ravel()]).T    \n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
